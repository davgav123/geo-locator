% Format teze zasnovan je na paketu memoir
% http://tug.ctan.org/macros/latex/contrib/memoir/memman.pdf ili
% http://texdoc.net/texmf-dist/doc/latex/memoir/memman.pdf
% 
% Prilikom zadavanja klase memoir, navedenim opcijama se podešava 
% veličina slova (12pt) i jednostrano štampanje (oneside).
% Ove parametre možete menjati samo ako pravite nezvanične verzije
% mastera za privatnu upotrebu (na primer, u b5 varijanti ima smisla 
% smanjiti 
\documentclass[12pt,oneside]{memoir}

% Paket koji definiše sve specifičnosti mastera Matematičkog fakulteta
\usepackage{matfmaster}
%
% Podrazumevano pismo je ćirilica.
%   Ako koristite pdflatex, a ne xetex, sav latinički tekst na srpskom jeziku
%   treba biti okružen sa \lat{...} ili \begin{latinica}...\end{latinica}.
%
% Opicija [latinica]:
%   ako želite da pišete latiniciom, dodajte opciju "latinica" tj.
%   prethodni paket uključite pomoću: \usepackage[latinica]{matfmaster}.
%   Ako koristite pdflatex, a ne xetex, sav ćirilički tekst treba biti
%   okružen sa \cir{...} ili \begin{cirilica}...\end{cirilica}.
%
% Opcija [biblatex]:
%   ako želite da koristite reference na više jezika i umesto paketa
%   bibtex da koristite BibLaTeX/Biber, dodajte opciju "biblatex" tj.
%   prethodni paket uključite pomoću: \usepackage[biblatex]{matfmaster}
%
% Opcija [b5paper]:
%   ako želite da napravite verziju teze u manjem (b5) formatu, navedite
%   opciju "b5paper", tj. prethodni paket uključite pomoću: 
%   \usepackage[b5paper]{matfmaster}. Tada ima smisla razmisliti o promeni
%   veličine slova (izmenom opcije 12pt na 11pt u \documentclass{memoir}).
%
% Naravno, opcije je moguće kombinovati.
% Npr. \usepackage[b5paper,biblatex]{matfmaster}

% Pomoćni paket koji generiše nasumičan tekst u kojem se javljaju sva slova
% azbuke (nema potrebe koristiti ovo u pravim disertacijama)
\usepackage{pangrami}

% Paket koji obezbeđuje ispravni prikaz ćiriličkih italik slova kada
% se koristi pdflatex. Zakomentarisati ako na sistemu koji koristite ovaj
% paket nije dostupan ili ako ne radi ispravno.
\usepackage{cmsrb}

% Ostali paketi koji se koriste u dokumentu
\usepackage{listings} % listing programskog koda

\renewcommand\lstlistingname{К\^{о}д}
\renewcommand\lstlistlistingname{К\^{о}д}

\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.94,0.94,0.94}

\lstdefinestyle{mystyle}{
    basicstyle=\sffamily,
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{red},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    %numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    basicstyle=\small
}

\lstset{style=mystyle}

% Datoteka sa literaturom u BibTex tj. BibLaTeX/Biber formatu
\bib{matfmaster-primer}

% Ime kandidata na srpskom jeziku (u odabranom pismu)
\autor{Давид Гавриловић}
% Naslov teze na srpskom jeziku (u odabranom pismu)
\naslov{Дистрибуирана обрада геопросторних података}
% Godina u kojoj je teza predana komisiji
\godina{2022}
% Ime i afilijacija mentora (u odabranom pismu)
\mentor{др Милена Вујошевић Јаничић, ванредни професор\\ Универзитет у Београду, Математички факултет}
% Ime i afilijacija prvog člana komisije (u odabranom pismu)
\komisijaA{др Саша Малков, ванредни професор\\ Универзитет у Београду, Математички факултет}
% Ime i afilijacija drugog člana komisije (u odabranom pismu)
\komisijaB{др Mирко Спасић, доцент\\ Универзитет у Београду, Математички факултет}
% Ime i afilijacija trećeg člana komisije (opciono)
% \komisijaC{}
% Ime i afilijacija četvrtog člana komisije (opciono)
% \komisijaD{}
% Datum odbrane (obrisati ili iskomentarisati narednu liniju ako datum odbrane nije poznat)
\datumodbrane{септембар 2022.}

% Apstrakt na srpskom jeziku (u odabranom pismu)
\apstr{%
\pangrami
}

% Ključne reči na srpskom jeziku (u odabranom pismu)
\kljucnereci{програмски језик Скала, дистрибуирана обрада података, \textit{Hadoop}, \textit{Apache Spark}, геопросторни подаци, \textit{OpenStreetMap}}

\begin{document}
% ==============================================================================
% Uvodni deo teze
\frontmatter
% ==============================================================================
% Naslovna strana
\naslovna
% Strana sa podacima o mentoru i članovima komisije
\komisija
% Strana sa posvetom (u odabranom pismu)
%\posveta{некоме}
% Strana sa podacima o disertaciji na srpskom jeziku
\apstrakt
% Sadržaj teze
\tableofcontents*

% ==============================================================================
% Glavni deo teze
\mainmatter
% ==============================================================================


\chapter{Увод}
\label{chp:uvod}

Данас се, због развоја интернета, друштвених мрежа и сличног, генерише велика количина података. Обрада тих података је битна јер се из њих могу добити разне корисне информације. Због бољих перформанси у односу на појединачне машине, за обраду великих количина података се користе дистрибуирани системи, који су у могућности да поделе податке на делове и да те делове паралелно обрађују на појединачним машинама.

Један од примера велике количине података су геопросторни подаци. То су подаци који представљају локације на географској мапи и њихов опис. Могу се користити за конструкцију географских мапа, лоцирање разних објеката на мапи, одређивање оптималних линија градског превоза и слично. Пример јавно доступног скупа геопросторних података је \textit{OpenStreetMap} који садржи локације одређене географском дужином и ширином као и информације о томе шта се на локацијама налази (аутобуска станица, пешачки прелаз, црква, ресторан и слично).

Циљ рада је израда апликације \textit{Geo-locator}. Њена функција је да филтрира геопросторне податке и да за сваку локацију која представља битан туристички податак (хотел, хостел, ресторан, паб, болницу и слично) одреди којој држави припада. Филтрирани подаци се касније приказују на географској мапи света. Коришћени подаци припадају скупу \textit{OpenStreetMap} и обрађују се на дистрибуиран начин коришћењем програмског језика Скала и алата \textit{Apache Spark}.

Апликација је израђена у програмском језику Скала, па су у поглављу \ref{chp:scala} описани њени основни концепти. Такође, Скала је заступљена и у алатима за дистрибуирану обраду података. У поглављу \ref{chp:dist_sis} је приказан концепт дистрибуираних система као и мотивација за њихово постојање. У истом поглављу су описани структура, начин рада и компоненте дистрибуираног система \textit{HDFS}. Приказан је и начин рада, али и недостаци \textit{MapReduce}-а, прве парадигме за дистрибуирану обраду података. Опис алата \textit{Apache Spark} и приказ његовог начина функционисања, архитектуре и компоненти се налази у поглављу \ref{chp:spark}, док се детаљнији опис скупа \textit{OpenStreetMap} и његових елемената налази у поглављу \ref{chp:osm}. Опис апликације, њене компоненте и технологије које се користе у њеној изради су приказане у поглављу \ref{chp:app}. У последњем поглављу се налази закључак, у коме се налазе коментари о раду и апликацији, као и могућа унапређења.

%У овом раду је приказан опис дистрибуираних система, мотивација за њихово постојање и њихова организација. Такође је урађено и поређење између система који се састоје од једне машине и система који чини више машина. Детаљно су описани 
%
%\textit{Apache Spark} је алат отвореног кода који се користи за дистрибуирану обраду података. \textit{Spark} дели податке на делове који се називају партиције, које се засебно и паралално обрађују на поједничним машинама дистрибуираног система. У раду је детаљније приказана архитектура овог алата, начин функционисања и компоненте. Да би се извршила обрада података, \textit{Spark} користи дистрибуиране структуре података, \textit{RDD} и \textit{DataFrame}, које су описане у овом раду. 
%
%Из разлога што је \textit{Apache Spark} написан у програмском језику Скала, али и због саме заступљености Скале у алатима који се користе за дистрибуирану обраду података, описани су и њени основни концепти.

\chapter{Програмски језик Скала}
\label{chp:scala}

Скала (енг. \textit{Scala}) је виши програмски језик заснован на функционалној и објектно оријентисаној парадигми  \cite{scala_prog}. Име је добила од енглеске речи \textit{scalable} јер је дизајнирана тако да се развија са потребама корисника. Има широк спектар примена и може се користити за писање једноставних скрипти, али и у изградњи великих и комплексних система.

Настала је 2001. године на Швајцарском федералном институту за технологију у Лозани (фра. \textit{École Polytechnique Fédérale de Lausanne}) и њен творац је Мартин Одерски (енг. \textit{Martin Odersky}). Прва званична верзија је изашла 20. јануара 2004. године. Данас је широко распростањена и веома је заступљена у заједници отвореног кода у пројектима као што су \textit{Apache Spark} \cite{apache_spark}, \textit{Apache Kafka} \cite{apache_kafka}, \textit{Apache Flink} \cite{apache_flink} и \textit{Akka} \cite{scala_akka}.

\section{Особине језика Скала}
\label{sec:osоб_scala}

% шта урадити... Склонити интерпретер... вратитити контролу тока... рефакторисати примере да буду без интерпретера

Скала је спој две парадигме, објектно оријентисане и функционалне, па стога поседује велики број особина. Поред тога, компајлира се на исти начин као и језик Јава, са којим постоје одређене сличности.

\subsection{Објектно оријентисан и функционалан језик}
\label{subsec:scala_obj_prog}

Скала је у потпуности објектно оријентисан језик. То значи да је свака вредност која се дефинише објекат, као и да је свака акција која се позива метод \cite{scala_prog}. На пример, уколико се врши одузимање два цела броја, позива се метод назван ,,$-$`` (минус). Тај метод је дефинисан у класи која представља целе бројеве, \textit{Int}. 

Поред тога што је објектно оријентисан језик, Скала је и функционалан језик \cite{scala_prog}. Функционално програмирање је засновано на двама принципима. Први је да су функције вредности првог реда. То значи да се функције посматрају на исти начин као и други типови, на пример целобројни тип или тип ниске. Такође, функције је могуће прослеђивати другим функцијама, функције могу бити повратна вредност неке друге функције и функције се могу складиштити у променљивама.

Други принцип је да функције које се позивају немају бочне ефекте. Једна функција има улогу само да пресликава улаз у одговарајући излаз. То значи да ће сваки позив једне функције са истом вредношћу улазних аргумената, увек резултовати истом излазном вредношћу, независно од тога када се функција позива током извршавања програма. Другачији назив за ову особину је референцијална транспарентност.

Из овога произлази да функционални језици користе непроменљиве структуре података \cite{scala_prog}. То су такве структуре за које важи да се подаци унутар њих не мењају. Уколико до промене мора доћи, сама структура се не мења, већ се од ње конструише тотално нова, са измењеним вредностима.

Међутим, иако подржава писање функционалног кода, Скала није чисто функционалан језик, што значи да је ипак могуће дефинисати функције које поседују бочне ефекте и да је могуће користити структуре података које се могу мењати. Ипак, у Скали се писање кода који није функционалан не препоручује и увек се тежи поштовању концепата функционалне парадигме.

\subsection{Повезаност са језиком Јава}
\label{subsec:scala_komp}

Скала се компајлира у Јавин ЈВМ бајтк\^{о}д (енг. \textit{Java JVM bytecode}) \cite{scala_prog}. То значи да Скала може користити Јава класе, методе и типове. На пример, Скалин објектни целобројни тип у својој имплементацији користи примитивни еквивалент из Јаве. Поред тога, Скала може користити Јава к\^{о}д и обогатити га на неки начин, као на пример додавањем неке методе у већ постојећу класу. Време извршавања Скала програма приближно је једнако времену извршавања Јава програма.

Међутим, иако се компајлирају на исти начин, програми написани у језику Скала често садрже мањи број линија од оних написаних у језику Јава. У неким случајевима се очекује да је к\^{о}д чак дупло краћи. Краћи програми доводе до тога да је к\^{о}д лакше писати и разумети, али и до мање вероватноће прављења грешака.

Један од многих примера како Скала смањује број линија у односу на Јаву је приказан у кодовима \ref{lst:scala_java_class_declaration} и \ref{lst:scala_scala_class_declaration} који представљају начине декларисања класе у та два програмска језика. У Скали се не мора декларисати конструктор, што доводи до смањења броја линија кода.

\begin{lstlisting}[caption={Декларација класе у језику Јава}, language=Java, label={lst:scala_java_class_declaration}]
class MyClass {  
  private int index;
  private String name;
  public MyClass(int index, String name) {
    this.index = index;
    this.name = name;
  }
}
\end{lstlisting}

\begin{lstlisting}[caption={Декларација класе у језику Скала}, language=Scala, label={lst:scala_scala_class_declaration}]
class MyClass(index: Int, name: String)

\end{lstlisting}

\subsection{Статичка типизираност}
\label{subsec:scala_stat_tip}

Статичка типизираност значи да се типови променљивих закључују за време компајлирања програма. Супротан термин је динамичка типизираност, која закључује типове за време извршавања. Оба приступа имају своје предности и мане. Скала је статички типизиран језик и поседује веома напредан систем типова.

Статичка типизираност доноси предности које доводе до лакшег откривања грешака приликом писања кода \cite{scala_prog}. На пример, у статички типизираним програмима се током компајлирања сазнаје да ли је примењена нека операција на објекат типа над којим та операција није дозвољена. Поред тога, статичка типизираност чини рефакторисање кода поузданијим. На пример, након измене метода се са сигурношћу може рећи да се повратни тип није променио.

Скала није само статички типизиран језик већ је и језик који аутоматски закључује типове у току компајлирања. На пример, када се декларише нека променљива, нема увек потребе назначити и њен тип, пошто га компајлер често може аутоматски одредити. То значи да се следеће две линије кода (пример \ref{lst:scala_scala_type_declaration}) понашају еквивалентно.

\begin{lstlisting}[caption={Декларација променљиве са и без експлицитног навођења типа}, language=Scala, label={lst:scala_scala_type_declaration}, basicstyle=\small]
// primer 1
val x: Int = 10
// primer 2
val x = 10
\end{lstlisting}

Скала програмер не мора експлицитно да наводи типове, али је то  често пожељно. Навођење типова осигурава да ће к\^{о}д заправо користити тип који му је намењен. Такође, навођење типова побољшава читљивост програма и представља вид документације.

\section{Интерпретер за Скалу}
\label{sec:scala_interpr}

Скала је језик који се може интерпретирати. Да би се покренуо интерпретер за Скалу потребно је покренути команду \textit{scala} (к\^{о}д \ref{lst:scala_scala_interpreter_example}).

\begin{lstlisting}[language=Scala, caption={Интерпретер за Скалу}, label={lst:scala_scala_interpreter_example}, basicstyle=\small]
$ scala
Welcome to Scala 2.13.6
Type in expressions for evaluation. Or try :help.

scala>
\end{lstlisting}

Након што се унесе к\^{о}д у интерпретер и притисне ентер, покреће се интерпретација написаног кода и излаз се приказује у конзоли. Пример извршавања кода у интерпретеру је приказан у коду \ref{lst:scala_interpreter_code_example}.

\begin{lstlisting}[language=Scala, caption={Пример извршавања кода у интерпретеру}, label={lst:scala_interpreter_code_example}, basicstyle=\small]
scala> 20 + 100
val res0: Int = 120
\end{lstlisting}

Излаз покренуте команде је аутоматски генерисана променљива типа \textit{Int} названа \textit{res0} у којој ће се налазити резултат унетог израчунавања. Новонастала променљива се може користити у наставку извршавања.

%\begin{lstlisting}[language=Scala, caption={Коришћење резултатских променљивих}, label={lst:scala_res0_example}]
%scala> res0 + 100
%val res1: Int = 220
%\end{lstlisting}

%Уколико је потребно само исписати вредност у конзоли без креирања нове променљиве може се користити функција \textit{print()}.

%\begin{lstlisting}[language=Scala, caption={Функција \textit{print}}, label={lst:scala_interpret_print_func}]
%scala> print(20 + 100)
%120
%
%scala> print("Hello!")
%Hello!
%\end{lstlisting}

\section{Типови}
\label{sec:scala_tip}

Сви примитивни типови Јаве имају свој одговарајући еквивалент у Скали и када се типови у Скали компајлирају у Јавин бајтк\^{о}д, превешће се баш у те типове \cite{scala_prog}. На пример, логички тип у Скали, \textit{scala.Boolean} је еквивалент Јавином примитивном типу \textit{boolean}. Исто важи и за друге примитивне типове Јаве попут целобројног (\textit{Int}) и типова са покретним зарезом (\textit{Float} и \textit{Double}).

Поред њих постоје и уграђени сложени типови попут ниске (\textit{String}), торке (\textit{Tuple}), низа (\textit{Array}) и других. Како је Скала објектно оријентисан језик, могу се дефинисати и додатни типови уколико за тим има потребе, али о томе више речи у одељку \ref{subsec:scala_klase}.

Сваки тип, долази са скупом оператора који се могу применити на објекте тог типа. Скала је написана тако да је сваки оператор заправо један метод дефинисан у класи која представља тип. Постоје различите врсте оператора попут аритметичких, логичких и битовских.

\section{Променљиве}
\label{sec:scala_prom}

У Скали се променљиве дефинишу преко кључне речи \textit{var}. Како је Скала типизиран језик, свака променљива je одређена типом. У коду \ref{lst:scala_var_values} је приказан пример коришћења променљиве у Скали.

\begin{lstlisting}[language=Scala, caption={Променљиве у Скали}, label={lst:scala_var_values}, basicstyle=\small]
scala> var x: Int = 10
var x: Int = 10

scala> x + 10
val res0: Int = 20

scala> x = 20
// mutated x

scala> x = "some string"
           ^
       error: type mismatch;
        found   : String("some string")
        required: Int
\end{lstlisting}

Поред променљивих, у Скали постоје и именоване вредности. Дефинишу се кључном речи \textit{val} и могу се посматрати као променљиве којима се не може променити вредност. Пример коришћења именоване вредности је приказан у коду \ref{lst:scala_val_reassignment}.

\begin{lstlisting}[language=Scala, caption={Именоване вредности у Скали}, label={lst:scala_val_reassignment}, basicstyle=\small]
scala> val x: Int = 10
val x: Int = 10

scala> x + 20
val res0: Int = 30

scala> x = 20
         ^
       error: reassignment to val
\end{lstlisting}

\section{Контрола тока}
\label{sec:scala_kontr_toka}

Скала поседује уграђене стандардне наредбе за контролу тока, \textit{if} за гранање, \textit{while} за петље и \textit{for} за итерирање кроз колекције \cite{scala_prog}. У примеру \ref{lst:scala_flow_control} су те наредбе приказане у скалиној синтакси.

\begin{lstlisting}[language=Scala, caption={Наредбе за контролу тока}, label={lst:scala_flow_control}]

if (bool izraz) {
  // izraz je evaluiran u istinitu vrednost
} else {
  // izraz je evaluiran u neistinitu vrednost
}

while (bool izraz) {
  // dok se izraz evaluira u istinitu vrednost
}

for (element <- kolekcija) {
  // operacije nad elementom
}

\end{lstlisting}

%kolekcija.foreach(funkcija koje se poziva za svaki element kolekcije)


\section{Функције}
\label{sec:scala_funk}

Скала делом припада функционалној парадигми па су стога функције веома битан део језика. Функција се дефинише кључном речи \textit{def} након које редом следе име функције, опциона листа њених аргумената са њиховим типовима раздвојених зарезом, тип повратне вредности функције, знак $=$ и на крају тело функције. Синтаксa дефиниције функције је приказана у коду \ref{lst:scala_function_template}.

\begin{lstlisting}[language=Scala, caption={Дефиниција функције у Скали}, label={lst:scala_function_template}, basicstyle=\small]
def imeFunkcije(argument1: tip1, ...): povratni_tip = {
  // telo funkcije
}

\end{lstlisting}

У коду \ref{lst:scala_function_add_example} је приказана функција која сабира два цела броја и враћа добијени резултат. 

\begin{lstlisting}[language=Scala, caption={Дефиниција функције која сабира два цела броја}, label={lst:scala_function_add_example}, basicstyle=\small]
def saberi(x: Int, y: Int): Int = {
  x + y
}
\end{lstlisting}

Последња линија тела функције ће увек бити њена повратна вредност али се поред тога она може назначити и наредбом \textit{return}. Уколико се функција састоји од само једне линије кода, могу се изоставити витичасте заграде које означавају почетак и крај тела фунције. Поред тога, због закључивања типова се може изоставити и тип повратне вредности. Дакле, функција \textit{saberi} из претходног примера се краће може записати на следећи начин:

\begin{lstlisting}[language=Scala, caption={Краћи запис функције \textit{saberi} и пример њеног позива}, label={lst:scala_function_add_example_simplified}, basicstyle=\small]
scala> def saberi(x: Int, y: Int) = x + y
def saberi(x: Int, y: Int): Int

scala> saberi(40, 2)
val res0: Int = 42
\end{lstlisting}

Тип повратне вредности се у неким случајевима ипак не сме изоставити \cite{scala_prog}. На пример, када се користи рекурзија. Такође, функција не мора да враћа никакву вредност. У том случају се повратни тип означава са \textit{Unit}.

Све функције су вредности првог реда у Скали па имају и свој тип. Тип функције је представљен заградама у којима се налазе типови њених аргумената након којих следи знак $=>$ праћен типом повратне вредности. Тип функције \textit{saberi}, која поседује два аргумента типа \textit{Int}, као и исти повратни тип, је приказан у коду \ref{lst:scala_function_add_example_type}.

\begin{lstlisting}[language=Scala, caption={Тип функције \textit{saberi}}, label={lst:scala_function_add_example_type}, basicstyle=\small]
(Int, Int) => Int
\end{lstlisting}

Експлицитно навођење типова дозвољава декларацију функција вишег реда, функција које као аргументе имају друге функције. Пример \ref{lst:scala_function_high_order_example} приказује функцију која као аргумент има функцију која има два аргумента и повратну вредност типа \textit{Int}.

\begin{lstlisting}[language=Scala, caption={Функција вишег реда}, label={lst:scala_function_high_order_example}, basicstyle=\small]
scala> def visiRed(f: (Int, Int) => Int, x: Int, y: Int) = {
  f(x, y)
}
def visiRed(f: (Int, Int) => Int, x: Int, y: Int): Int
\end{lstlisting}

Тип првог аргумента ове функције одговара типу функције \textit{saberi}, па се она може проследити новонаписаној функцији.

\begin{lstlisting}[language=Scala, caption={Прослеђивање функције функцији}, label={lst:scala_function_add_high_order}, basicstyle=\small]
scala> visiRed(saberi, 100, 200)
val res0: Int = 300
\end{lstlisting}

%Све функције које су до сада приказане су поседовале идентификатор, односно име. Међутим, то није неопходно и могуће је дефинисати функцију без имена. Такве функције се називају ламбда функције (енг. \textit{lambda functions}). Оне се обично користе када је нека функција потребна само једном, на пример у неком изразу, и не позива се никад више у коду. Декларишу се тако што се у заградама наводи низ аргумената са типовима, знак $=>$ и након тога повратна вредност. Пример ламбда функције која сабира два броја је приказан у коду \ref{lst:scala_function_lambda_example}.

%\begin{lstlisting}[language=Scala, caption={Пример ламбда функције}, label={lst:scala_function_lambda_example}]
%scala> (x: Int, y: Int) => x + y
%val res0: (Int, Int) => Int = $Lambda$2582/1961424035@2207eb9f
%\end{lstlisting}
%
%Ламбда функције се могу проследити функцијама вишег реда, па претходно дефинисана функција \textit{visiRed} може бити позвана на следећи начин:
%
%\begin{lstlisting}[language=Scala, caption={Прослеђивање ламбда функције другој функцији}, label={lst:scala_functions_lambda_high_order}]
%scala> visiRed((x: Int, y: Int) => x + y, 100, 200)
%val res0: Int = 300
%\end{lstlisting}
%
%\noindent У овом примеру, функција \textit{saberi} је замењена ламбда функцијом истог понашања, што није довело до промене коначног резултата. 

\section{Објектнo оријентисана својства језика}
\label{sec:scala_oop}

У овом одељку ће бити детаљније описана објектно оријентисана парадигма језика Скала.

\subsection{Класе}
\label{subsec:scala_klase}

Као и у Јави, у Скали класа представља шаблон према коме се праве објекти. Да би се креирао објекат дате класе, користи се кључна реч \textit{new}. У коду \ref{lst:scala_oop_class_instance} је приказан  пример дефиниције и инстанцирања класе (напомена: усправна линија у интерпретеру за Скалу представља нови ред док ознака $@$ праћена знаковима након назива класе представља инстанцу класе у меморији).

\begin{lstlisting}[language=Scala, caption={Дефиниција и инстанцирање класе у Скали}, label={lst:scala_oop_class_instance}, basicstyle=\small]
scala> class MyClass {
     | }

scala> val mc = new MyClass
val mc: MyClass = MyClass@e700eba
\end{lstlisting}

Унутар класе се дефинишу поља (енг. \textit{fields}) и методе (енг. \textit{methods}), који се заједно једним именом називају чланови (енг. \textit{members}) \cite{scala_prog}. Поља су променљиве које се дефинишу са \textit{val} или \textit{var} док су методи функције које описују неко понашање и дефинишу се на исти начин као и обичне функције.

\begin{lstlisting}[language=Scala, caption={Чланови класе}, label={lst:scala_oop_members_class}, basicstyle=\small]
scala> class MyClass {
     |  val field = 0
     |  def method() = print(field)
     | }

scala> val mc = new MyClass
val mc: MyClass = MyClass@e700eba

\end{lstlisting}

%scala> mc.field
%mval res0: Int = 0
%
%scala> mc.method()
%0

Сваком члану се додељује једно правило приступа којим се одређује опсег из ког се том члану може приступити. У Скали постоје три правила приступа и то су:

\begin{itemize}
\item \textbf{\textit{private}}, приступ унутар класе;
\item \textbf{\textit{protected}}, приступ унутар класе и класа које наслеђују ту класу;
\item \textbf{\textit{public}}, приступ изван класе (подразумевана вредност која се не наводи).
\end{itemize}

%Пример \textit{private} приступа је приказан у коду \ref{lst:scala_oop_private_access}. Сваки покушај приступа приватној променљивој ван класе ће резултовати грешком.
%
%\begin{lstlisting}[language=Scala, caption={Пример правила приступа \textit{private}}, label={lst:scala_oop_private_access}, basicstyle=\small]
%scala> class MyClass {
%     |  private val field = 0
%     |  def method() = print(field)
%     |  }
%class MyClass
%
%\end{lstlisting}

%scala> val mc = new MyClass
%val mc: MyClass = MyClass@6a6e9289
%scala> mc.field
%          ^
%       error: value field in class MyClass cannot be accessed as a member of MyClass from class 

Поља се могу дефинисати ван тела класе, што је и Скалин стандард (к\^{о}д \ref{lst:scala_oop_field_outside}). Због тога се класа може написати уз помоћ мањег броја линија. 

\begin{lstlisting}[language=Scala, caption={Дефиниција поља ван тела класе}, label={lst:scala_oop_field_outside}, basicstyle=\small]
scala> class MyClass(private val field: Int = 0) {
     |    def method() = print(field)
     |  }

\end{lstlisting}

%scala> val m = new MyClass
%val m: MyClass = MyClass@5d8e4fa8

У претходном примеру, поље \textit{field} поседује подразумевану вредност која ђе се том пољу увек доделити приликом инстанцирања класе \cite{scala_prog}. Међутим, она се не мора навести и, уколико је то случај, пољима се мора експлицитно доделити вредност приликом инстанцирања. Пример је приказан у коду \ref{lst:scala_oop_field_explicit}.

\begin{lstlisting}[language=Scala, caption={Инстанцирање класе без подразумеваних вредности поља}, label={lst:scala_oop_field_explicit}, basicstyle=\small]
scala> class MyClass(private val field: Int) {
     |    def method() = print(field)
     |  }

scala> val mc = new MyClass
                ^
       error: not enough arguments for constructor MyClass: (field: Int): MyClass.
       Unspecified value parameter field.
     
scala> val mc = new MyClass(10)
val mc: MyClass = MyClass@7d332e20
\end{lstlisting}

\subsection{Наслеђивање}
\label{subsec:scala_nasled}

Наслеђивање се остварује на исти начин као у Јави, преко кључне речи \textit{extends} \cite{scala_prog}. Инстанцирање поља наткласе из поткласе се дефинише у самој дефиницији наслеђивања, након речи \textit{extends} (Пример \ref{lst:scala_oop_extends_example}). Сва поља наткласе која немају подразумеване вредности се инстанцирају на овај начин. Предефинисање чланова наткласе се врши на исти начин као у Јави, преко кључне речи \textit{override}.

\begin{lstlisting}[language=Scala, caption={Наслеђивање у Скали}, label={lst:scala_oop_extends_example}, basicstyle=\small]
// natklasa
scala> class MyClass(private val field: Int) 

// potklasa
scala> class MyExtendedClass(
     |  private val fieldForParent: Int,
     |  private val newField: Int
     | ) extends MyClass(fieldForParent) // prosledjivanje vrednosti natklasi
class MyExtendedClass

\end{lstlisting}

У претходном примеру ће се приликом инстанцирања поткласе инстанцирати и поља наткласе. Да би се непотребно заузимање меморије избегло, потребно је изоставити навођење речи \textit{val} (или \textit{var}) испред заједничког поља приликом дефинисања поткласе (к\^{о}д \ref{lst:scala_oop_extends_cool_way}). У овом случају, поље које се прослеђује наткласи мора имати исти идентификатор у поткласи и наткласи.

\begin{lstlisting}[language=Scala, caption={Наслеђивање изастављењем речи \textit{val}}, label={lst:scala_oop_extends_cool_way}, basicstyle=\small]
// natklasa
scala> class MyClass(private val field: Int) 

// potklasa
scala> class MyExtendedClass(
     |  field: Int, // polje za prosledjivanje
     |  private val newField: Int
     | ) extends MyClass(field) // prosledjivanje vrednosti natklasi
class MyExtendedClass

\end{lstlisting}

%scala> val mec = new MyExtendedClass(10, 20)
%val mec: MyExtendedClass = MyExtendedClass@42ba9b22

\subsection{Апстрактне класе}
\label{subsec:scala_abs}

Апстрактне класе се дефинишу коришћењем кључне речи \textit{abstract} која се наводи пре речи \textit{class} која означава класу, на исти начин као у Јави \cite{scala_prog}. Апстрактне класе се не могу инстанцирати, али се могу наследити од стране других класа.

\begin{lstlisting}[language=Scala, caption={Апстрактна класа у Скали}, label={lst:scala_oop_abstract_class_example}, basicstyle=\small]
scala> abstract class MyAbstractClass {
     | }
class MyAbstractClass
\end{lstlisting}

%\begin{lstlisting}[language=Scala, caption={Инстанцирање апстрактне класе}, label={lst:scala_oop_abstract_class_instance_example}]
%scala> abstract class MyAbstractClass {
%     | }
%class MyAbstractClass
%
%scala> val mac = new MyAbstractClass
%                 ^
%       error: class MyAbstractClass is abstract; cannot be instantiated
%\end{lstlisting}

\subsection{Синглтон објекти}
\label{subsec:scala_sing_obj}

За разлику од Јаве, у Скали не постоје статичка поља. Уместо тога постоје синглтон објекти (енг. \textit{singleton object}) \cite{scala_prog}. Дефинишу се на исти начин као и класе, с тим што се користи кључна реч \textit{object} уместо \textit{class}. Добили су име по томе што представљају класу која има тачно једну инстанцу. Инстанцирање објекта се извршава аутоматски. Сви чланови објекта се могу посматрати као статички чланови у Јава класи.

\begin{lstlisting}[language=Scala, caption={Коришћење синглтон објекта}, label={lst:scala_oop_object_example}, basicstyle=\small]
scala> object MyObject {
     |   def hello() = print("Hello from object")
     | }

scala> MyObject.hello()
Hello from object
\end{lstlisting}

%Уколико објекат дели своје име са неком класом, а при томе се налазе у истом фајлу, тај објекат се назива објекат пратилац (енг. \textit{companion object}) \cite{scala_prog}. Паралелно, та класа се назива класа пратилац тог објекта. Класа или објекат који су пратиоци могу да приступе приватним члановима свог пратиоца (к\^ {о}д \ref{lst:scala_oop_companions_example}).
%
%\begin{lstlisting}[language=Scala, caption={Пример пратиоца}, %label={lst:scala_oop_companions_example}]
%object Kvadrat {
%    def izracunajPovrsinu(a: Int) = a * a
%}
%
%class Kvadrat(a: Int) {
%    def povrsina = Kvadrat.izracunajPovrsinu(a)
%}
%
%scala> val k = new Kvadrat(10)
%val k: Kvadrat = Kvadrat@6cb2d5ea
%
%scala> k.povrsina
%val res0: Int = 100
%
%\end{lstlisting}

\subsubsection{Метод \textit{main}}
\label{subsubsec:scala_oop_main_app}

Да би се апликација написана у Скали покренула потребно је дефинисати објекат који у себи садржи метод \textit{main} \cite{scala_prog}. Тај метод представља улазну тачку у сваку апликацију написану у Скали.

\begin{lstlisting}[language=Scala, caption={Пример метода \textit{main}}, label={lst:scala_oop_main_method}, basicstyle=\small]
scala> object Main {
     |  def main(args: Array[String]): Unit = {
     |      print("Hello")
     | 	}
     | }
\end{lstlisting}

\subsection{Својствa}
\label{subsec:scala_traits}

Основна јединица наслеђивања у Скали се назива својство (енг. \textit{Trait}) \cite{scala_prog}. Унутар својства се наводе поља и методи који се могу користити у класама које их имплементирају, односно наслеђују. Разлика између наслеђивања својства и класе је та што је дозвољено наследити једну класу, док је могуће наследити више од једног својства. Скала својство je веома слично Јавином интерфејсу, са разликом да својство може садржати и дефиниције метода и поља, а не само декларације. Међутим, својство је више од тога и унутар њега се може урадити све што се може урадити унутар Скала класе.

Дефинишe се на исти начин као и класa с тим што се уместо кључне речи \textit{class} користи реч \textit{trait} (к\^{o}д \ref{lst:scala_oop_trait_example}). Унутар својства се декларишу и дефинишу поља и методи које класе које га имплементирају могу користити.

\begin{lstlisting}[language=Scala, caption={Скала својство}, label={lst:scala_oop_trait_example}, basicstyle=\small]
scala> trait MyTrait {
     |   def myMethod(): Unit
     |   val x: Int = 10
     | }
trait MyTrait
\end{lstlisting}

\noindent Својство се додаје класи на исти начин као када се означава наследство, помоћу речи \textit{extends}. 

\begin{lstlisting}[language=Scala, caption={Додавање својства класи}, label={lst:scala_oop_traits_extends_example}, basicstyle=\small]
scala> class MyClass extends MyTrait
class MyClass

scala> val mc = new MyClass
val mc: MyClass = MyClass@774189d0

scala> mc.x
val res0: Int = 10
\end{lstlisting}

Уколико класа којој се додељује својство већ наслеђује неку класу или неко друго својство, додељивање се мора извршити преко кључне речи \textit{with} \cite{scala_prog}. Свако ново својство које се додаје у овом случају се мора додати након нове речи \textit{with}. Примери су приказани у коду \ref{lst:scala_oop_extends_traits_with}.

\begin{lstlisting}[language=Scala, caption={Наслеђивање више својстава}, label={lst:scala_oop_extends_traits_with}, basicstyle=\small]
scala> class MyExtendedClass extends MyClass with MyTrait1 with MyTrait2
class MyExtendedClass

scala> class MyExtendedTraits extends MyTrait1 with MyTrait2
class MyExtendedTraits
\end{lstlisting}

%Скала \textit{trait} се може користити и као тип, а вредност променљиве тог типа мора бити класа која наслеђује тај \textit{trait}.
%
%\begin{lstlisting}[language=Scala, caption={\textit{Trait} као тип}, label={lst:scala_oop_traits_types}, basicstyle=\small]
%scala> trait MyTrait
%trait MyTrait
%
%scala> class MyClass extends MyTrait
%class MyClass
%
%scala> val mc: MyTrait = new MyClass
%val mc: MyTrait = MyClass@339cedbb
%\end{lstlisting}
%
%
%\subsection{\textit{Case} класе}
%\label{subsec:scala_case_klase}
%
%У језику Скала, поред стандардних, постоји још једна врста класе названа \textit{case} класа. Постоје три разлике између ове врсте класа и обичних:

%\begin{itemize} 
%\item Променљиве ове класе се инстанцирају без кључне речи \textit{new};
%\item Свако поље ове класе мора имати префикс \textit{val};
%\item \textit{Case} класа садржи аутоматски генерисане методе $==$, \textit{toString()} и \textit{hashCode()}.
%\end{itemize}
%
%\begin{lstlisting}[language=Scala, caption={Пример коришћења \textit{case} класа}, label={lst:scala_oop_case_class_example}]
%scala> case class MyCaseClass(val field: Int)
%class MyCaseClass
%
%scala> val mcc = MyCaseClass(100)
%val mcc: MyCaseClass = MyCaseClass(100)
%
%scala> mcc.toString
%val res0: String = MyCaseClass(100)
%\end{lstlisting}
%
%Једна од предности ових класа је та да се могу користити у конструкту специфичном за функционалне језике, поклапању образаца (енг. \textit{pattern matching}), који ће бити детаљније описан у секцији \ref{sec:scala_patt_match}.

%\subsection{Хијерархија класа}
%\label{subsec:scala_class_hier}
%
%У Скали, као и у Јави, постоји хијерархија наслеђивања типова (слика \ref{fig:scala_types_hier}) \cite{scala_prog}. На врху се налази класа \textit{Any} коју свака Скала класа наслеђује, имплицитно или експлицитно. Овај тип поседује два подтипа, \textit{AnyVal} и \textit{AnyRef}. Први је корен свим Скала типовима који представљају вредности. То су \textit{Byte}, \textit{Short}, \textit{Char}, \textit{Int}, \textit{Long}, \textit{Float}, \textit{Double}, \textit{Boolean} и \textit{Unit}. Друга, \textit{AnyRef}, представља родитељску класу свим референцама у Скали, слично као класа \textit{Object} у Јави. Потомци овог типа се инстанцирају преко кључне речи \textit{new}.
%
%На дну референтних типова се налази класа \textit{Null}. Вредност овог типа се може доделити било којој референци. Једина класа која наслеђује \textit{Null} је \textit{Nothing}. Класа \textit{Nothing} нема вредност и не може се доделити ниједној променљивој.
%
%\begin{figure}[!ht]
%  \centering
%  \includegraphics[width=1\textwidth]{pictures/scala_hier.png}
%  \caption{Хијерархија Скала типова}
%  \label{fig:scala_types_hier}
%\end{figure}

\section{Колекције}
\label{sec:scala_coll}

Скала поседује велики број уграђених колекција, променљивих и непроменљивих. Неке од њих су низови, листе и торке.

\subsection{Низови}
\label{subsec:scala_arrays}

Скала низ (енг. \textit{array}) је променљива структура која представља низ података \cite{scala_prog}. Променљива је у смислу да се вредности елемената у низу могу мењати, док је број елемената фиксиран. Сваки низ садржи елементе истог типа и може се креирати навођењем иницијалних елемената или његове дужине. Уколико се наведе дужина, сви елементи ће бити иницијализовани на подразумевану вредност жељеног типа.

\begin{lstlisting}[language=Scala, caption={Инстанцирање низа у Скали}, label={lst:scala_coll_array_example}, basicstyle=\small]
scala> val a1 = Array(1, 2, 3)
val a1: Array[Int] = Array(1, 2, 3)

scala> val a2 = new Array[Int](3)
val a2: Array[Int] = Array(0, 0, 0)
\end{lstlisting}

%У претходном примеру се у другом случају инстанцира нова класа коришћењем наредбе \textit{new} док у првом то није случај. Разлог је тај што се у првом случају позива метод \textit{apply()} који креира инстанцу низа. Поред тога, у првом случају је Скала компајлер аутоматски закључио тип низа на основу прослеђених елемената, док је у другом тип морао бити експлицитно назначен.

Елементу низа се приступа слично као у Јави, са тим што се уместо угластих заграда користе обичне. На сличан начин се извршава и измена једног елемента.

\begin{lstlisting}[language=Scala, caption={Приступ и измена елемента низа}, label={lst:scala_coll_array_get_set}, basicstyle=\small]
scala> val a = Array(1, 2, 3)
val a: Array[Int] = Array(1, 2, 3)

scala> a(0)
val res0: Int = 1

scala> a(0) = 100

scala> a
val res1: Array[Int] = Array(100, 2, 3)
\end{lstlisting}

\subsection{Листе}
\label{subsec:scala_lists}

Скала листе представљају непроменљиву колекцију елемената истог типа \cite{scala_prog}. Разлика листе у Скали у односу на Јавину је та што је Скала листа увек непроменљива, док Јава листа може бити променљива. 

Инстанцира се навођењем елемената. Приступ елементу листе се извршава на исти начин као и у случају низа. Пошто су листе непроменљиве, измена вредности елемената није дозвољена.

\begin{lstlisting}[language=Scala, caption={Пример листе у Скали}, label={lst:scala_coll_lists_example}, basicstyle=\small]
scala> val l = List("a", "b", "c")
val l: List[String] = List(a, b, c)

scala> l(0)
val res0: String = a

scala> l(0) = "try"
       ^
       error: value update is not a member of List[String]
       did you mean updated?
\end{lstlisting}

%Спајање листи се извршава оператором $:::$ \cite{scala_prog}. Приликом позива овог оператора се не извршава додавање елемената једне листе на другу, већ је резултат нова листа. Овај метод се може користити и за спајање више од две листе.

%\begin{lstlisting}[language=Scala, caption={Спајање листи}, label={lst:scala_coll_lists_new_list}]
%scala> val l1 = List(1, 2, 3)
%val l1: List[Int] = List(1, 2, 3)
%
%scala> val l2 = List(4, 5, 6)
%val l2: List[Int] = List(4, 5, 6)
%
%scala> val l3 = List(7, 8, 9)
%val l3: List[Int] = List(7, 8, 9)
%
%scala> l1 ::: l2 ::: l3
%val res0: List[Int] = List(1, 2, 3, 4, 5, 6, 7, 8, 9)
%\end{lstlisting}

%Нове листе се могу инстанцирати и коришћењем оператора $::$, који као аргументе прима елемент и листу истог типа од којих конструише нову листу где елемент додаје на почетак листе.

%\begin{lstlisting}[language=Scala, caption={Пример оператора ::}, label={lst:scala_coll_lists_head_op}]
%scala> val l = List(1, 2, 3)
%val l: List[Int] = List(1, 2, 3)
%
%scala> 10 :: l
%val res0: List[Int] = List(10, 1, 2, 3)
%\end{lstlisting}

%Коришћењем овог оператора се може извршити надовезивање елемената на празну листу (пример \ref{lst:scala_coll_lists_head_op_nill}). У Скали се празна листа означава кључном речи \textit{Nil}.

%\begin{lstlisting}[language=Scala, caption={Додавање елемената на празну листу}, label={lst:scala_coll_lists_head_op_nill}]
%scala> val l = 1 :: 2 :: 3 :: 4 :: Nil
%val l: List[Int] = List(1, 2, 3, 4)
%\end{lstlisting}

\subsection{Торке}
\label{subsec:scala_tuple}

Непроменљива колекција која садржи елементе различитог типа се назива торка (енг. \textit{Tuple}) \cite{scala_prog}. Ова структура података се може користити када је потребно вратити више различитих вредности функције. Торка се инстанцира навођењем елемената између заграда. Елементу се приступа оператором \_Х где је \textit{Х} редни број елемента унутар торке.

\begin{lstlisting}[language=Scala, caption={Пример торке у Скали}, label={lst:scala_coll_tuple_example}, basicstyle=\small]
scala> val t = (1, "string123", Array(1, 2, 3))
val t: (Int, String, Array[Int]) = (1,string123,Array(1, 2, 3))

scala> t._1
val res0: Int = 1

scala> t._3
val res1: Array[Int] = Array(1, 2, 3)
\end{lstlisting}

%\subsection{Мапе}
%\label{subsec:scala_maps}
%
%Мапе су колекције за рад са кључ-вредност паровима. Постоје мутабилне (\textit{collection.mutable.Map}) и имутабилне (\textit{collection.immutable.Map}). Имутабилне су подразумеване и користе се уколико се експлицитно не наведе супротно.
%
%Дефинишу се навођењем низа кључ-вредност парова, раздвојених знаком $\rightarrow$. Сви кључеви и све вредности међусобно морају бити истог типа. Приступ вредностима се врши преко назива кључа, методом $()$.
%
%\begin{lstlisting}[language=Scala, caption={Пример мапе у Скали}, label={lst:scala_app_maps_example}, basicstyle=\small]
%scala> val m1 = Map("k1" -> "v1", "k2" -> "v2")
%val m1: scala.collection.Map[String,String] = Map(k1 -> v1, k2 -> v2)
%
%scala> m1("k1")
%val res0: String = v1
%
%\end{lstlisting}
%
%Разлика између мутабилних и имутабилних мапа је та што је код мутабилних могуће изменити број елемената, као и саме елементе, док имутабилна мапа то не подржава.

\begin{comment}

\begin{lstlisting}[language=Scala, caption={Измена и додавање елемента код мутабилних и имутабилних мапа}, label={lst:scala_coll_maps_mutable_immutable}, basicstyle=\small]
// mutabilna mapa
scala> val mutableM = mutable.Map("k1" -> "v1")
val mutableM: scala.collection.mutable.Map[String,String] = HashMap(k1 -> v1)

scala> mutableM("k1") = "vred1" //izmena elementa

scala> mutableM("k2") = "vred2" // dodavanje elementa

scala> mutableM
val res0: scala.collection.mutable.Map[String,String] = HashMap(k1 -> vred1, k2 -> vred2)

// imutabilna mapa
scala> val immutableM = Map("k1" -> "v1")
val immutableM: scala.collection.Map[String,String] = Map(k1 -> v1)

scala> immutableM("k1") = "vred1" // izmena elementa
       ^
       error: value update is not a member of scala.collection.Map[String,String]

scala> immutableM("k2") = "vred2" // dodavanje elementa
       ^
       error: value update is not a member of scala.collection.Map[String,String]

\end{lstlisting}

\section{Поклапање образаца}
\label{sec:scala_patt_match}

Поклапање образаца (енг. \textit{pattern matching}) је честа карактеристика функционалних језика. Слична је наредби \textit{switch} из Јаве, али нуди више могућности од ње \cite{scala_prog}. Састоји се од селектора, који представља израз или променљиву, кључне речи \textit{match} и низа случајева унутар витичастих заграда. Сваки случај се састоји од знака $=>$ који се налази између вредности са којом се селектор поклапа и кључне речи \textit{case} са леве стране и израза који ће бити резултат поклапања са десне.

\begin{lstlisting}[language=Scala, caption={Поклапање образаца у Скали}, label={lst:scala_coll_patt_match}, basicstyle=\small]
selector match {
	case value1 => result1
	case value2 => result2
	...
}
\end{lstlisting}

Разлике између ове нарeдбе и Јавине наредбе \textit{switch} су:

\begin{itemize} 
\item У случају успешног поклапања, \textit{match} наредба увек резултује неком вредношћу;
\item Када се пронађе одговарајућа вредност, друге вредности након ње се не разматрају -- није потребно користити наредбу \textit{break};
\item Уколико ниједна вредност не одговара селектору, појављује се \textit{MatchError} (увек треба покрити све могуће вредности селектора).
\end{itemize}

%\subsection{Примери коришћења}
%\label{subsec:scala_match_exaples}

Поклапање образаца је веома моћан механизам и користи се у великом броју случајева. Један од њих је поклапање константи и приказан је у коду \ref{lst:scala_patt_match_match_const_example}. Поред поклапања константи, поклапање образаца се може користити за поклапање вредности променљивих, поклапање типова или поклапање конструктора.

\begin{lstlisting}[language=Scala, caption={Поклапање константи}, label={lst:scala_patt_match_match_const_example}, basicstyle=\small]
scala> def describe(x: Any) = x match {
     | case 5 => "five"
     | case "hello" => "hi!"
     | case _ => "something else"
     | }
     
scala> describe(5)
val res1: String = five

scala> describe(1001)
val res2: String = something else
\end{lstlisting}

У претходном примеру је искоришћена ознака $\_$. Назива се џокер (енг. \textit{wildcard}) и поклапа се са било којом вредности селектора.

\begin{lstlisting}[language=Scala, caption={Џокер у поклапању образаца}, label={lst:scala_patt_match_wildcard}, basicstyle=\small]
scala> def describe(x: Int) = x match {
     | case 10 => "x je 10"
     | case _ => "x nije 10"
     | }
def describe(x: Int): String

scala> describe(10)
val res1: String = x je 10

scala> describe(100)
val res2: String = x nije 10

\end{lstlisting}

\end{comment}

%Поклапање образаца се користи и за поклапање променљивих \cite{scala_prog}. У примеру \ref{lst:scala_patt_match_variable_match_example} променљива \textit{something} одговара било којој вредности селектора, слично као џокер, али се преко ње та вредност преноси са десне стране ознаке $=>$.
%
%\begin{lstlisting}[language=Scala, caption={Поклапање променљивих}, label={lst:scala_patt_match_variable_match_example}]
%scala> val expr = "some expression"
%val expr: String = some expression
%
%scala> expr match {
%     | case ""        => print("empty string")
%     | case something => print("matched: " + something)
%     | }
%matched: some expression
%\end{lstlisting}
%
%Поред вредности селектора, могуће је поклапати и његов тип, уколико је потребно имплементирати другачије понашање за другачије типове.
%
%\begin{lstlisting}[language=Scala, caption={Поклапање типова}, label={lst:scala_patt_match_types_example}]
%scala> trait MyTrait
%trait MyTrait
%
%scala> class MyClass_1 extends MyTrait
%class MyClass_1
%
%scala> class MyClass_2 extends MyTrait
%class MyClass_2
%
%scala> def describe(x: MyTrait) = x match {
%     |   case mc1: MyClass_1 => "MyClass_1"
%     |   case mc2: MyClass_2 => "MyClass_2"
%     |   case _ => "some other class"
%     | }
%def describe(x: MyTrait): String
%
%scala> describe(new MyClass_1)
%val res1: String = MyClass_1
%
%scala> describe(new MyClass_2)
%val res2: String = MyClass_2
%\end{lstlisting}
%
%Могуће је комбиновати претходне примере и извршити поклапања типова и променљивих уз помоћ једног поклапања образаца \cite{scala_prog}. Пример \ref{lst:scala_patt_match_generalSize} приказује функцију \textit{generalSize(x: Any)} која се понаша другачије у односу на то ког типа је њен аргумент.

%\begin{lstlisting}[language=Scala, caption={Пример поклапања типова и променљивих}, label={lst:scala_patt_match_generalSize}]
%scala> def generalSize(x: Any) = x match {
%     |   case s: String => s.length
%     |   case m: Map[_, _] => m.size
%     |   case _ => -1
%     |  }
%def generalSize(x: Any): Int
%
%scala> generalSize("some string")
%val res1: Int = 11
%
%scala> generalSize(12)
%val res2: Int = -1
%\end{lstlisting}

%Поклапање конструктора се користи када је потребно извршити поклапање класа које наслеђују заједничку класу. 
%
%\begin{lstlisting}[language=Scala, caption={Поклапање конструктора}, label={lst:scala_patt_match_constr_match_example}]
%scala> abstract class Animal
%     | case class Mammal(name: String) extends Animal
%     | case class Bird(name: String) extends Animal
%class Animal
%class Mammal
%class Bird
%
%scala> def caseClassesPatternMatching(animal: Animal) = animal match {
%     |  case Mammal(name) => s"I'm a $name, a mammal"
%     |  case Bird(name) => s"I'm a $name, a bird"
%     |  case _ => "I'm an unknown animal"
%     |}
%def caseClassesPatternMatching(animal: Animal): String
%\end{lstlisting}

%\section{Optional и Either}
%\label{sec:scala_opt_eith}=
%optional i either tipovi

%\section{Implicit vred}
%\label{sec:scala_impl_vals}
%implicits
%if requested

\chapter{Дистрибуирана обрада података}
\label{chp:dist_sis}

У последњих неколико година се генерише огромна количина података \cite{volume_data}. Друштвене мреже, видео садржај, куповина преко интернета и Интернет ствари (енг. \textit{Internet of Things}) на дневном нивоу производе петабајте података, а у будућности се очекује пораст тог тренда. Како је често проблем обрадити огромне количине података на једној машини, индустријски стандард су постали кластери који раде са подацима на дистрибуиран начин.

% да ли овде направити увод у мерне јединице???
\begin{comment}

\begin{center}
\begin{tabular}{|c|c|}
	\hline
 	Мерна јединица меморије & Вредност \\ \hline
	Бит & 0 или 1 \\ \hline
	Бајт & 8 бита \\ \hline 	
 	Килобајт & 1024 бајта \\ \hline
 	Мегабајт & 1024 килобајта \\ \hline
 	Гигабајт & 1024 мегабајта \\ \hline
 	Терабајт & 1024 гигабајта \\ \hline
 	Петабајт & 1024 терабајта \\ \hline
 	Егзабајт & 1024 петабајта \\ \hline
\end{tabular}
\end{center}

\end{comment}

% подаци су свуда око нас бла бла бла???

\section{Доба података} % подаци данас?
\label{sec:dist_motivacija}

Према истраживању \cite{volume_data} приказаном на једноj од водећих интернет платформи за податке који се користе у пословању, \textit{Statista}, количина података која се производи се тренутно може мерити у зетабајтима (милионима петабајта). Исто истраживање приказује да ће се наредних година тај број удвостручити. Приказ тренда пораста генерисања података је приказан на слици \ref{fig:kolicina_podataka}.

Корист од података је огромна и велики број компанија их користи за разне намене, од побољшања искуства корисника који користе њихове услуге, до разних предвиђања у пословању. Из тих разлога се доста улаже у складиштење, обраду, истраживање и анализу података. Подаци су се раније, док још увек нису генерисани у количинама у којима се то дешава данас, обрађивали на појединачним машинама, али се убрзо испоставило да такав приступ има своја ограничења.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.8\textwidth]{pictures/Total_data_volume_worldwide_2010_2025_statista.png}
  \caption{Kоличина података по години у зетабајтима \cite{volume_data}}
  \label{fig:kolicina_podataka}
\end{figure}

\section{Скалирање система}
\label{sec:skaliranje}

У контексту система, скалирање означава могућност система да се прилагоди количини података који се уз помоћ њега обрађују. Постоје два начина скалирања уређаја који врше обраду података (слика \ref{fig:skaliranje}). Први начин је вертикално скалирање (енг. \textit{vertical scaling}) или \textit{scale-up} \cite{hadoop_beginner}. У овом приступу се унапређује једна машина, на пример, додавањем веће количине меморије или појачавањем снаге процесора. Предност овог приступа је што се након унапређења машине не мора мењати логика апликација које се на њој извршавају. Али негативна особина је што постоји ограничење до ког се машина може унапредити, па стога постоји и ограничење у количини података које она може обрадити. Такође, у случају грешке, цео систем престаје са радом, пошто се састоји од само једне машине.

Други приступ је хоризонтално скалирање (енг. \textit{horizontal scaling}) или \textit{scale-out} \cite{hadoop_beginner}. У овом случају се не унапређује једна машнина, већ се, уколико је потребна додатна снага, додаје нова машина у систем. Добра особина овог приступа је што је често јефтиније додати неколико нових машина у систем него унапредити процесор неколико пута на истој машини. Још једна веома добра одлика је ефикасност. Када постоји неколико машина могуће је на свакој од њих обрађивати један део података, што је огромна предност у односу на вертикално скалирање. Међутим, хоризонтално скалирање доноси додатан скуп проблема. Потребно је имплементирати цео систем на потпуно другачији начин, омогућити машинама да раде заједно и координисати их, као и обрадити грешке који се могу десити на појединачним машинама. Како су наведене предности значајне, а мане се могу превазићи, данашњи стандард у обради великих количина података је хоризонтално скалирање.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.9\textwidth]{pictures/scaling.png}
  \caption{Врсте скалирања система}
  \label{fig:skaliranje}
\end{figure}

\section{Организација дистрибуираних система}
\label{sec:scaling_osobine}

У оквиру хоризонталног скалирања свака машина у систему обрађује један део података и на тај начин доприноси коначном резултату, због чега машине морају да комуницирају једна са другом \cite{hadoop_beginner}. Поред тога, могуће је да постоје подаци који су потребни свим машинама у систему, што може довести до такмичења уређаја за приступ тим подацима. Уколико се подаци налазе на само једној машини у систему, све друге машине ће јој приступити, тако да су могућности система у том случају ограничене могућностима те једне машине којој све остале приступају. Поред тога, на тој машини се може догодити некакав проблем због ког она може да престане да функционише, што би изазвало престанак рада целог система.

Да би се потенцијални проблеми избегли, систем треба да функционише тако да уређаји који су у њему раде независно од других уређаја истог система, као и да престанак рада једне машине не утиче на систем у целини. Другим речима, треба направити систем који се као целина понаша исправно, чак и при појави фаталних грешака. 

У оваквим системима акценат је на софтверу, а не на хардверу и идеја је да се систем може направити од уређаја који су релативно јефтини и масовно доступни \cite{hadoop_beginner}. Такође, циљ је да се избегава премештање података међу уређајима, па се подаци, уколико је то могуће, обрађују на машини на којој се налазе.

\section{Систем \textit{Hadoop}}
\label{sec:hadoop}

Први широко доступан систем који поседује претходно наведене карактеристике је развила компанија \textit{Google} која је 2003. године објавила научни рад на ту тему \cite{gfs}. У раду је представљен дистрибуирани фајл систем, назван \textit{Google file system} или скраћено \textit{GFS}. Систем је написан у програмском језику \textit{C++}. Намена овог система је да се користи за складиштење великих количина података. Већ следеће године, \textit{Google} је објавио нови научни рад о парадигми за ефикасну обраду велике количине података на кластеру \cite{gmr}. Парадигма је названа \textit{MapReduce} и њена намена је да се користи за обраду података складиштених у \textit{GFS}-у.

Недуго након тога, уз помоћ научних радова компаније \textit{Google}, настао је пројекат отвореног кода (енг. \textit{оpen source}) назван \textit{Hadoop} са идејом да имплементира карактеристике које поседују \textit{Google}-ови \textit{GFS} и \textit{MapReduce} и да се као такав користи за складиштење и ефикасну обраду падатака на кластеру сачињеном од релативно јефтиних машина \cite{hadoop_beginner}. Највећи делови система \textit{Hadoop} су \textit{Hadoop distributed file system}, скраћено \textit{HDFS}, и парадигма \textit{MapReduce}, који су заправо јавно доступни еквиваленти \textit{Google}-ових технологија. Њихови логои су приказани на слици \ref{fig:hdfs_mr_logo}.

Укратко, \textit{HDFS} је фајл систем који користи хоризонтално скалирање машина за складиштење огромних количина података \cite{hadoop_beginner}. Због боље поузданости користи репликацију, где се сваки фајл копира неколико пута и онда се те копије чувају на различитим уређајима у систему.

\textit{MapReduce} је парадигма за обраду података, која се састоји из два дела названа \textit{Мap} и \textit{Reduce}, по којима је и добила име \cite{hadoop_beginner}. Улога дела \textit{Map} је да чита података из \textit{HDFS}-а у деловима и трансформише их, док \textit{Reduce} прикупља резултате обраде фазе \textit{Map} и спаја их у један. Обрада се извршава на истим машинама \textit{HDFS}-а на којима се подаци и налазе, чиме се избегава њихово премештање на неку другу машину.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.8\textwidth]{pictures/hdfs_mr_logo.png}
  \caption{Логои \textit{HDFS}-а и \textit{MapReduce}-а}
  \label{fig:hdfs_mr_logo}
\end{figure}

Поред поменуте две компоненте, постоји и трећа, а то су \textit{HDFS}-апликације \cite{hadoop_learning}. Оне се надовезују на \textit{HDFS} и \textit{MapReduce} тако што их користе за, редом, складиштење и обраду података. Најпознатије су \textit{Apache Hive} \cite{apache_hive} и \textit{Apache Pig} \cite{apache_pig}, али поред њих постоје и многе друге, само мање заступљене. На слици \ref{fig:hadoop_aplikacije} су приказане компоненте \textit{Hadoop}-а.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.7\textwidth]{pictures/hadoop_apps.png}
  \caption{Упрошћен приказ \textit{Hadoop}-а}
  \label{fig:hadoop_aplikacije}
\end{figure}

\section{Дистрибуирани фајл систем \textit{HDFS}}
\label{sec:hdfs}

\textit{HDFS}, скраћено од \textit{Hadoop distributed file system} је дистрибуирани систем, што значи да складишти податке на више машина које ће се у даљем тексту звати чворови (енг. \textit{nodes}). %Скуп машина које раде заједно на такав начин да се могу посматрати као једна целина се назива кластер (енг. \textit{cluster}). 

\subsection{Структура \textit{HDFS}-а}
\label{subsec:hdfs_nodes}

Постоје две врсте чворова, именски чвор (енг. \textit{name node}) и чвор података (енг. \textit{data node}). Функционишу по надређени-подређени (енг. \textit{master-slave}) архитектури, где именски чвор има улогу надређеног. Чворови су приказани на слици \ref{fig:hadoop_nodovi}.

Унутар система \textit{HDFS} се налази један примарни именски чвор чија је улога да управља фајл системом и да регулише приступ подацима који се налазе на њему \cite{hadoop_arch_guide}. Он садржи информације о фајловима, као што су, између осталих, име, локација у систему где се фајл налази, последњи датум измене фајла као и правила приступа. Поред примарног, \textit{HDFS} може имати и неколико секундарних именских чворова који представљају резервне копије.

Чворови података имају улогу да складиште фајлове система \cite{hadoop_arch_guide}. Поред тога, на овим чворовима се извршава обрада података. Чворови података су задужени за операције над фајловима као што су читање, мењање и брисање. Они ће извршити неку од тих операција само када им именски чвор то нареди.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.92\textwidth]{pictures/node_types.png}
  \caption{Врсте чворова у \textit{HDFS}-у}
  \label{fig:hadoop_nodovi}
\end{figure}

Уколико апликација жели да приступи \textit{HDFS}-у, она ће прво комуницирати са именским чвором и од њега затражити фајлове који јој требају. Након тога, именски чвор проверава да ли та апликација поседује потребне дозволе за приступ тим фајловима и ако их она има, послаће јој њихову локацију у фајл систему. Након тога се може извршити жељени приступ. 

\subsection{Основне карактеристике \textit{HDFS}-а}
\label{subsec:hdfs_osobine}

Сваки фајл у \textit{HDFS}-у је подељен на делове који се називају блокови чија је величина обично 128 мегабајта \cite{hadoop_arch_guide}. Блокови се често не налазе на истим чворовима у систему, што значи да се један фајл чува на неколико физички раздвојених машина. Ту може да настане проблем због тога што једна од тих машина може да се поквари и због тога престане са радом. У том случају ће сви блокови складиштени на тој машини нестати. Да би се губљење фајлова избегло, \textit{HDFS} сваки блок реплицира неколико пута и након тога оригинални блок и његове реплике распоређује по систему. Ако један од блокова фајла неочекивано нестане, увек је могуће приступити једној од његових реплика. Генерисане реплике се чувају на чворовима података, док се информације о томе ком фајлу реплике припадају налазе на именском чвору.

Блок ће се увек реплицирати одређен, фиксиран, број пута. Чворови података повремено шаљу сигнале именском чвору о доступности реплика. На тај начин ће именски чвор увек имати информацију о томе колико је пута сваки блок реплициран у систему и на основу тога може да, уколико тај број падне испод неке задовољавајуће вредности, направи нове реплике тог блока \cite{hadoop_arch_guide}.

\textit{HDFS} је конструисан тако да може да настави са радом у случају фаталних грешака на чворовима података. Међутим, могућа је појава грешака и на именском чвору и те грешке могу довести до пада целокупног система. Такви проблеми се решавају чувањем резервних копија именског чвора и због њих се у случају престанка његовог рада не губе информације. Резервне копије се праве у одређеним временским интервалима да би подаци на њима били ажурни. Резервне копије и репликација су битне за целокупну робусност система, односно поузданости података. Концепти \textit{HDFS}-а су приказани на слици \ref{fig:hadoop_sistem}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1\textwidth]{pictures/hdfs_components_basic.png}
  \caption{Основне \textit{HDFS}-компоненте}
  \label{fig:hadoop_sistem}
\end{figure}

\textit{HDFS} је систем за кога важи \textit{пиши једном, читај више пута} (енг. \textit{write-once, read-many)}. Када се фајл постави унутар \textit{HDFS}-а више се не може мењати \cite{hadoop_beginner}. Уколико се фајл мора изменити долази до креирања новог фајла који замењује стари. Иако такав приступ није ефикасан, апликације које обрађују велике количине података се обично заснивају на томе да се подаци не мењају, па се очекује да за променама неће бити потребе или ће такви случајеви бити ретки. Такође, још једна од особина \textit{HDFS}-а је да има добре перформансе у случајевима када је потребан велики проток података, на пример у случају читања великих фајлова.

% https://www.quora.com/Is-HDFS-an-append-only-file-system-Then-how-do-people-modify-the-files-stored-on-HDFS.

\section{Парадигма \textit{MapReduce}}
\label{sec:mr}

\textit{МapRreduce} је парадигма која се користи за обраду података који су складиштени у \textit{HDFS}-у \cite{hadoop_beginner}. Користи приступ подели и завладај (енг. \textit{divide and conquer}) приликом обраде тако да више машина паралелно обрађује по један део података.

Парадигма је заснована на концептима функционалног програмирања и функцијама које се често користе у обради низова и листи. Те фунције су \textit{map} и \textit{reduce}. Прва од постојеће листе креира нову тако што на сваки елемент листе примени неку фунцију и од њега направи нови елемент. Друга од целе листе производи једну вредност. На истим принципима фунционише и \textit{MapReduce}.

\textit{MapReduce} обрађује податке у неколико фаза \cite{hadoop_learning}. Прво, подаци се читају из \textit{HDFS}-а и након тога прослеђују машинама које се зову мапери (енг. \textit{mappers}). Те машине паралелно производе скуп привремених података који се након тога распоређују, сортирају и шаљу машинама које се зову редуктори (енг. \textit{reducers}). Фаза која распоређује податке се назива фаза мешања и сортирања (енг. \textit{shuffle and sort}). Задатак редуктора је да приме подскуп података и да паралелно произведу једну вредност од истих. На самом крају се резултат свих редуктора комбинује и добија се резултат читавог процеса \textit{MapReduce}, другачије названог и \textit{MapReduce}-задатак (енг. \textit{task}). Могуће је, уланчавањем, комбиновати \textit{MapReduce}-задатке, тако да излаз из једног буде улаз у други. Скуп повезаних \textit{MapReduce}-задатака се назива \textit{MapReduce}-апликација.

\subsection{\textit{MapReduce} из аспекта функција}
\label{subsec:mr_funck_asp}

Из аспекта функција, фазе пресликавања (енг. \textit{map}) и редуковања (енг. \textit{reduce}) се могу посматрати на следећи начин. Подразумевани формат је \textit{(кључ, вредност)} за који ће се због једноставности користити ознака \textit{(k, v)}. Током фазе пресликавања подаци се читају из \textit{HDFS}-а и деле на делове на које се паралелно примењује функција \textit{map} дефинисана од стране програмера. Паралелизам се постиже тако што се сваки део обрађује на засебној машини, маперу. Фаза пресликавања као улаз прима паровe \textit{(k, v)} и производи листу истог формата \cite{hadoop_learning}.

$$ list(k_1, v_1) \rightarrow map(list(k_1, v_1)) \rightarrow list(k_2, v_2) $$

Након тога се листе генерисане од мапера групишу тако што се за сваки кључ прави једна група коју ће обрадити један редуктор. Овај део обраде је мешање и сортирање. 

$$ list(k_2, v_2) \rightarrow shuffleAndSort(list(k_2, v_2)) \rightarrow k_2, list(v_2) $$

У последњој фази се на сваку од креираних група примењује функција \textit{reduce} која производи једну вредност за сваку групу \cite{hadoop_learning}. Овај процес је паралелизован и није могуће две групе података са различитим кључевима обрађивати на истој машини у истом тренутку. Паралелна редукција је могућа само ако је редукција дефинисана као асоцијативна и комутативна операција. Фаза редуковања прима кључ и листу вредности које му одговарају и као резултат производи једну вредност формата \textit{(k, v)}.

$$ k_2, list(v_2) \rightarrow reduce(k_2, list(v_2)) \rightarrow (k_3, v_3) $$

Коначан резултат се добија комбиновањем резултата свих редуктора и може се уписати у \textit{HDFS} или се искористити као улаз у други \textit{MapReduce}-задатак. У \textit{MapReduce}-апликацијама задатак програмера је да опише како ће се извршавати фазе пресликавања и редуковања, док ће се систем \textit{Hadoop} побринути за све остало: читање података, сортирање, паралелизацију, координацију и извршавање послова \cite{hadoop_beginner}.

Пример \textit{MapReduce}-апликације је приказан на слици \ref{fig:map_reduce} где је представљен процес пребројавања броја појављивања сваке речи у тексту. У приказаном примеру је улаз у мапере форматиран тако да је кључ редни број линије фајла, док је вредност текст линије. Улога мапера је да поделе текст на речи и да од њих направе листе парова формата \textit{(реч, 1)}. Након тога се парови који имају исту реч премештају на засебне редукторе који израчунавају колико пута се у почетном скупу појављује свака реч, сумирањем јединица.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1\textwidth]{pictures/mr_example_wordcount.png}
  \caption{Пример \textit{MapReduce}-апликације}
  \label{fig:map_reduce}
\end{figure}

% Oва парадигма je направљена да ради за податке у \textit{(кључ, вредност)} формату, а не за податке који имају дефинисану шему. Пример података који имају шему би биле табеле у релационим моделима. \cite{hadoop_beginner}

\subsection{Недостаци парадигме \textit{MapReduce}}
\label{subsec:nedost_mr}

\textit{MapReduce}-апликација се састоји од ланца \textit{MapReduce}-задатака, таквих да излаз једног задатка представља улаз у други (слика \ref{fig:mr_app_example}). Међутим, такав приступ има цену, а то је да се излаз генерисан од стране једног \textit{MapReduce}-задатка чува унутар \textit{HDFS}-а, одакле му приступају други \textit{MapReduce}-задаци којима је тај излаз потребан \cite{hadoop_learning}. Другим речима, међурезултати задатака се чувају на диску, што ствара додатне улазно/излазне операције и тиме успорава извршавање целокупне апликације. Поред тога, унутар парадигме \textit{MapReduce} не постоји аутоматски начин да се задаци заједно оптимизују, на пример комбиновањем, већ је за то задужен програмер.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.9\textwidth]{pictures/mr_app.png}
  \caption{Пример ланца \textit{MapReduce}-задатака}
  \label{fig:mr_app_example}
\end{figure}

Због поменутих недостатака се парадигма \textit{MapReduce} у данашње време ретко користи. Потиснута је од стране других технологија и алата, међу којима је и \textit{Apache Spark}  (поглавље \ref{chp:spark}).

\section{Преговарач ресурса \textit{Apache Yarn}}
\label{sec:yarn}

У првој верзији \textit{Hadoop}-а, \textit{MapReduce} је поред обраде великих количина података, за шта је примарно и намењен, имао додатне задатке, а то су заказивање \textit{MapReduce}-задатака и алокација и управљање ресурсима који су \textit{MapReduce}-апликацији потребни \cite{hadoop_learning}. Таква архитектура је знатно отежавала конструкцију апликација које користе \textit{MapReduce}, па су због тога, у другој верзији \textit{Hadoop}-а, одговорности \textit{MapReduce}-а раздвојене. \textit{MapReduce} је постао алат искључиво за обраду података, док је управљање ресурсима предато новој апликацији, са идејом да је \textit{MapReduce} током извршавања користи.

Резултат је менаџер ресурса (енг. \textit{resource manager}) отвореног кода назван \textit{Yarn} \cite{yarn} или \textit{yet another resource negotiator}. Његова улога је да распоређује задатке апликација које користе \textit{Hadoop}, али и да управља ресурсима који су тим апликацијама потребни  \cite{hadoop_learning}. Конструисан је да не буде специфичан само за \textit{MapReduce}, већ пружа интерфејс ка \textit{Hadoop}-у разним апликацијама међу којима је и \textit{Apache Spark}. Разлика у архитектури у различитим верзијама \textit{Hadoop}-а је приказана на слици \ref{fig:yarn_hadoop_versions}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1\textwidth]{pictures/mr_yarn_hadoop_versions.png}
  \caption{Разлика у архитектури између \textit{Hadoop} верзија}
  \label{fig:yarn_hadoop_versions}
\end{figure}

\subsection{Архитектура \textit{Yarn}-а}
\label{subsec:yern_arch}

Улога \textit{Yarn}-а је искључиво да распореди извршавање задатака на кластеру и обезбеди им ресурсе потребне за њихово извршавање \cite{hadoop_learning}. Све остало, попут надгледања система, праћења прогреса апликација, обраде грешака и сличног, је имплементирано у коду апликације која га користи. % Разлог томе је идеја да \textit{Yarn} буде што је више могуће самосталан, да би различите врсте апликација могле да га користе.

Састоји се од две главне компоненте, менаџера ресурса (енг. \textit{resource manager}) и менаџера чвора (енг. \textit{node manager}) \cite{hadoop_learning}. Улога првог менаџера је да управља ресурсима читавог кластера, док други управља ресурсима машине на којој је покренут. То значи да ће кластер имати један менаџер ресурса и више менаџера чворa, по један за сваку машину у кластеру. Заједно, они управљају контејнерима (енг. \textit{container}), апстракцијом меморије, процесорске снаге и улазно-излазних операција потребних да би се извршио један део апликације на кластеру.

Менаџер ресурса је најбитнија компонента \textit{Yarn}-а и одговоран је за извршавање сваке апликације на кластеру \cite{hadoop_learning}. Састоји се од две компоненте, заказивача (енг. \textit{scheduler}) и менаџера апликације (енг. \textit{application manager}). Прва регулише распоред извршавања апликација, док друга прихвата апликације и преговара о алокацији првог контејнера који им је потребан.

Апликација која се покреће преко \textit{Yarn}-а се састоји из два дела. Први део је к\^{o}д који треба извршити на кластеру, док се други зове власник апликације (енг. \textit{application master}) \cite{hadoop_learning}. Његова улога је да преговара о ресурсима и прати прогрес и статус апликације. \textit{Yarn} нема информацију на који начин је успостављена комуникација између мастера апликације и кода који се извршава. Приказ архитектуре и компоненти \textit{Yarn}-а у случају извршавања две апликације на кластеру је приказан на слици \ref{fig:yarn_ar} (напомена: извршавају се две апликације, што значи да постоје два власника апликације).

Процес покретања апликације преко \textit{Yarn}-а се извршава следећим редоследом:

\begin{enumerate}
	\item Клијент пријављује апликацију.
	\item Менаџер ресурса алоцира контејнер на чвору у коме се покреће власник апликације.
	\item Власник апликације се региструје код менаџера ресурса.
	\item Власник апликације преговара о контејнерима са менаџером ресурса. У исто време, заказивач распоређује извршавање делова апликације.
	\item Власник апликације комунуцира са менаџером чвора о покретању потребних контејнера за извршавање апликације.
	\item К\^{о}д апликације се извршава унутар контејнера.
	\item Клијент преко менаџера ресурса и власника апликације прати прогрес апликације.
	\item Процес је завршен, власник апликације се одјављује од менаџера ресурса.
\end{enumerate}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.93\textwidth]{pictures/yarn_arch.png}
  \caption{Компоненте \textit{Yarn}-а у случају извршавања две апликације}
  \label{fig:yarn_ar}
\end{figure}

%Апликације се, користећи \textit{Yarn}, на кластеру покрећу преко клијента. Када \textit{Yarn} апликација започне са радом, клијент прво комуницира са менаџером ресурса и преко њега захтева иницијални контејнер на коме ће покренути мастер апликације. У већини случајева се мастер апликације покреће унутар једног контејнера у кластеру, исто као што се покреће и к\^{о}д апликације. Након тога почиње комуникација између покренутог мастера апликације и менаџера ресурса. Kомуникација се одвија тако што мастер апликације захтева од менаџера ресурса контејнере који су потребни апликацији и менаџер ресурса након тога шаље податке мастеру апликације о контејнерима које апликација може да користи. Користећи те информације, мастер апликације комуницира са менаџерима чворова који се налазе на истим машинама као и захтевани контејнери и пружа им спецификације о апликацији која треба да буде покренута у тим контејнерима. Након тога, менаџери чворова започињу извршавање апликације. Од овог тренутка, даље понашање апликације зависи од кода те апликације. \cite{hadoop_learning}

\textit{Yarn} има одговорност да омогући правилно извршавање апликацијама које се извршавају на \textit{HDFS}-у па стога мора обрадити грешке које се могу појавити \cite{hadoop_learning}. На пример, могуће је да једна од машина у кластеру престане се радом и тако постане неупотребљива. Када се то деси, менаџер ресурса ће менаџер чвора на тој машини означити мртвим и неће га више разматрати. Исто ће се десити и са контејнерима те машине. Такође, сваки контејнер који почне да користи више ресурса од оних који су му омогућени ће бити уништен, да не би изазивао проблеме другим апликацијама у систему.

\section{Остале компоненте \textit{Hadoop}-а}
\label{sec:ostale_komp_hadupa}

Екосистем \textit{Hadoop} чини велики број апликација разних примена које на неки начин користе \textit{HDFS}. Поред самог \textit{HDFS}-а, \textit{MapReduce}-а и \textit{Apache Yarn}-а у њега спадају и \textit{Apache Kafka} \cite{apache_kafka}, апликација за рад са токовима података, \textit{Apache Pig} \cite{apache_pig} и \textit{Apache Hive} \cite{apache_hive}, које се користе за обраду података и имплементиране су коришћењем \textit{MapReduce}-а. Поред њих постоје, на пример,  \textit{Presto} \cite{presto}, \textit{Apache Flume} \cite{apache_flume}, \textit{Apache Zookeeper} \cite{apache_zookeeper} али и многе друге. Приказ малог дела екосистема \textit{Hadoop} је приказан на слици \ref{fig:hadoop_ecosystem}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1\textwidth]{pictures/hadoop_ecosystem.png}
  \caption{Део екосистема \textit{Hadoop}}
  \label{fig:hadoop_ecosystem}
\end{figure}

\chapter{Алат \textit{Apache Spark}}
\label{chp:spark}

%Иако је \textit{MapReduce} парадигма обележила почетак доба обраде великих количина података, у данашње време се ретко користи. Примаран разлог томе су недовољно добре перформансе

\textit{Apache Spark} је алат отвореног кода. Настао je 2009. године на универзитету Беркли (енг. \textit{Berkeley}) у Калифорнији. Написан је у програмском језику Скала и дизајниран је са идејом да користи концепте функционалног програмирања. Постао је део фондације \textit{Apache} 2013. године. Од тада су избачене три верзије, редом назване, \textit{Spark} 1.0 (2013. године), \textit{Spark} 2.0 (2016. године) и \textit{Spark} 3.0 (2020. године).

Намењен је за дистрибуирану обраду велике количине података али се поред тога користи и за рад са токовима података (енг. \textit{streaming}), машинско учење и рад са графовима \cite{spark_guide}. Може се користити у програмским језицима Скала, Јава, \textit{Python} и \textit{R}. Иако је намењен за рад на кластерима, може се користити и на једној машини. На слици \ref{fig:spark_kompot} су приказане компоненте \textit{Apache Spark}-а. У овом поглављу ће детаљније бити приказане оне које се користе за обраду података.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1\textwidth]{pictures/spark_components.png}
  \caption{Компоненте \textit{Apache Spark}-a}
  \label{fig:spark_kompot}
\end{figure}

\section{Архитектура}
\label{sec:spark_arx}

Да би \textit{Spark} могао да приступа кластеру, потребно му је омогућити приступ уз помоћ менаџера ресурса. Иако \textit{Spark} поседује сопствени менаџер ресурса, могу се користити и други, попут \textit{Apache Yarn}-а. Након повезивања је могуће покренути \textit{Spark}-апликације на кластеру. 

Свака \textit{Spark}-апликација се састоји из једног контролног процеса (енг. \textit{driver process}) и једног или више процеса извршилац (енг. \textit{executor process}). Контролни процес је срце \textit{Spark}-апликације и има три задужења:

\begin{itemize}
	\item прикупљање информација о апликацији која се извршава;	
	\item конвертовање кода апликације у послове које треба извршити на извршиоцима;
	\item анализирање, распоређивање и планирање тих послова.
\end{itemize}

Извршилац има улогу да извршава посао који му контролни процес задаје. Поред тога, задужен је и за пријављивање стања извршавања тог посла контролном процесу. 

Унутар контролног процеса постоји одвојен процес назван \textit{Spark} контекст (енг. \textit{Spark context}) \cite{spark_guide}. Његова улога је да дефинише конекцију ка кластеру. Такође се користи и за креирање апстракција \textit{Spark}-а названих \textit{RDD} (поглавље \ref{sec:spark_rdd}). Једноставан приказ архитектуре \textit{Spark}-а је дат на слици \ref{fig:spark_arhtt}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.90\textwidth]{pictures/spark_arch.png}
  \caption{Архитектура \textit{Apache Spark}-а}
  \label{fig:spark_arhtt}
\end{figure}

Архитектура је заснована на истим концептима, независно од тога да ли се \textit{Spark} покреће у локалном моду, на једној машини, или на кластеру. Једина разлика је у томе што се на кластеру контролни процес и извршиоци налазе на различитим машинама, док ће локално бити покренути на истој.

\section{Партиције}
\label{sec:spark_partic}

Да би извршиоци могли паралелно да извршавају операције над подацима, \textit{Spark} податке дели на делове који се називају партиције (енг. \textit{partitions}) \cite{spark_guide}. Партиција је део колекције података који се налази на једној машини кластера. За партиције важи да се једна партиција увек обрађује од стране једног извршиоца, као и да један извршилац, у једном тренутку, обрађује податке тачно једне партиције. Дељење података на партиције у \textit{Spark}-у је аналогно дељењу података на делове  приликом извршавања фазе \textit{map} \textit{MapReduce}-а.

%Свака партиција се обрађује од стране једне машине, па је могуће извршити обраду већег броја партиција у исто време, на различитим машинама, чиме се постиже паралелизам. Такође, једна машина може обрађивати само једну партицију у једном тренутку

% свака партиција се обрађује од стране једне машине, па је могуће извршити обраду већег броја партиција у исто време, чиме се постиже паралелизам.

Уколико су подаци партиционисани само једном партицијом, биће обрађени од стране једног извршиоца у кластеру, независно од тога колико извршилаца постоји. Слично, уколико је креирано више партиција, али постоји само један извршилац, паралелизам неће постојати, због тога што постоји само једна машина која може обрадити податке.

\section{Апстракција података \textit{RDD}}
\label{sec:spark_rdd}

Основна јединица рада у \textit{Spark}-у се назива еластичан дистрибуирани скуп података (енг. \textit{resilient distributed dataset}), скраћено \textit{RDD}, и све операције са подацима се извршавају преко ње. \textit{RDD} је колекција елемената за које важи да су партиционисани по машинама кластера и да се над њима паралелно могу извршавати операције \cite{spark_rdd}. Постоји неколико начина преко којих се \textit{RDD} може креирати:

\begin{itemize}
\item читањем фајла који се налази на фајл систему (обично \textit{HDFS});
\item паралелизацијом --- процесом дељења у партиције колекције података програмског језика у коме се \textit{Spark} користи (слика \ref{fig:spark_rdd_creation_png});
\item од већ постојећег \textit{RDD}-ја применом \textit{Spark}-трансформације;
\item кеширањем постојећег \textit{RDD}-ја.
\end{itemize}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.80\textwidth]{pictures/spark_rdd_creation.png}
  \caption{Креирање \textit{RDD}-ja од колекције података}
  \label{fig:spark_rdd_creation_png}
\end{figure}

Данас се апстракција \textit{RDD} сматра застарелом и не користи се директно, већ постоје друге које су конструисане над њом и које су је потиснуле, углавном због бољих перформанси, попут \textit{Spark DataFrame}-a (поглавље \ref{sec:spark_df}). Битно је нагласити да се апстракција \textit{DataFrame} заснива на истим концептима као и \textit{RDD}, као и да се сваки \textit{DataFrame} к\^{о}д преводи у \textit{RDD} пре извршавања.

\subsection{Трансформације}
\label{subsec:spark_transf}

\textit{Spark} је конструисан по принципима функционалног програмирања, па су све његове структуре података непроменљиве, што значи да се након креирања оне не могу мењати \cite{spark_guide}. Пошто се подаци не могу мењати, свака операција која треба да их измени заправо креира потпуно нову структуру података. На пример, уколико постоји \textit{RDD} којем се мењају подаци које садржи, они се неће изменити непосредно, већ ће се од постојећег \textit{RDD}-ја направити нови који у себи садржи измењене податке.

Тај процес, где се од једног \textit{RDD}-ја применом наредби добија други, се назива трансформација (енг. \textit{transformation})  \cite{spark_guide}. Пратећи функционалне концепте, трансформације немају бочне ефекте, што значи да се од једног \textit{RDD}-ја применом истих трансформација, као резултат увек добија одговарајући \textit{RDD}, независно од тога када се те трансформације примењују. \textit{RDD} који трансформацијом настаје од другог \textit{RDD}-ја се назива зависни \textit{RDD} (енг. \textit{dependency}).

Постоје две различите врсте трансформација, уске (енг. \textit{narrow}) и широке (енг. \textit{wide}) \cite{spark_guide}. За уске трансформације важи да једна партиција у почетном \textit{RDD}-ју доприноси настајању највише једне партиције у зависном \textit{RDD}-ју. Са друге стране, широке трансформације су такве где једна партиција почетног \textit{RDD}-ја учествује у конструисању више партиција зависног \textit{RDD}-ја. Обе врсте трансформација су приказане на слици \ref{fig:sprk_trnsf}. Из приказане слике се за широку трансформацију може приметити да се подаци унутар једне партиције изворног \textit{RDD}-ја премештају у сваку партицију зависног \textit{RDD}-ја, слично као у оквиру фазе мешања и сортирања \textit{MapReduce}-а. Та појава се другачије назива мешање (енг. \textit{shuffle}).

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1\textwidth]{pictures/spark_transformation_types.png}
  \caption{Приказ врста \textit{Spark}-трансформација}
  \label{fig:sprk_trnsf}
\end{figure}

Постоји значајна разлика у перформансама узмеђу уских и широких трансформација \cite{spark_guide}. Код уских, \textit{Spark} извршава операције у меморији, док код широких пише резултате на диск и поново их распоређује по партицијама, што значајно успорава извршавање.

Све трансформације у \textit{Spark}-у припадају лењој евалуацији што значи да се не извршавају док се њихова вредности не затражи \cite{spark_guide}. За сваки ланац трансформација, \textit{Spark} креира \textit{план трансформација} који се извршава тек када је потребан њихов резултат. Евалуација скупа трансформација се у \textit{Spark}-у назива \textit{акција} (одељак \ref{subsec:spark_akc}).

%\begin{comment} Разлог оваквог приступа је ефикасност. Уколико \textit{Spark} поседује информацију о томе које ће се све трансформације извршити над структуром података, може оптимизовати цео процес на такав начин да добијање резултата траје најкраће могуће. \end{comment}

%\subsubsection{Лења евалуација}
%\label{subsubsec:spark_lazy_eval}

%Лења евалуација је начин евалуације у коме се израз евалуира тек након што се његова вредност затражи. Све трансформације у \textit{Spark}-у припадају лењој евалуацији \cite{spark_guide}  . За сваки ланац трансформација, \textit{Spark} креира \textit{план трансформација} који се извршава тек када се ланац трансформација евалуира. Разлог оваквог приступа је ефикасност. Уколико \textit{Spark} има информацију о томе које ће се све трансформације извршити над неком структуром података, може оптимизовати цео процес на такав начин да добијање резултата траје најкраће могуће. Евалуација скупа трансформација у \textit{Spark}-у се назива \textit{акција} (секција \ref{subsec:spark_akc}).

\subsection{Примери \textit{RDD}-трансформација}
\label{subsec:spark_transformation_types}

У \textit{Spark}-у постоји велики број трансформација, уских и широких. Неке од најпознатијих су приказане на слици \ref{fig:sprk_trnsf_examples} и то су:

\begin{itemize}
	\item \textbf{\textit{map}}, за сваки елемент почетног скупа података производи нови, применом неке операције;
	\item \textbf{\textit{flatMap}}, функционише исто као \textit{map} сa тим што сваки елемент почетног скупа производи нула, један или више елемената новог скупа (уколико за сваки елемент произведе тачно један нови елемент, ова трансформација је идентична \textit{map} трансформацији);
	\item \textbf{\textit{filter}}, од постојећег скупа елемената производи нови у коме се налазе они елементи почетног скупа који задовољавају некакав услов;
	\item \textbf{\textit{reduceByKey}}, редукује вредности са заједничким кључем --- редуковање се иницијално извршава по партицији, након чега се подаци распоређују по новим партицијама и поново редукују по кључу;
	\item \textbf{\textit{join}}, спаја два скупа елемената у један, где ће резултат бити скуп података у коме је вредност сваког кључа унија вредности тог кључа у засебним скуповима који учествују у спајању.
\end{itemize}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1\textwidth]{pictures/transf_examples.png}
  \caption{Примери \textit{RDD}-трансформација}
  \label{fig:sprk_trnsf_examples}
\end{figure}

Све \textit{RDD}-трансформације су део \textit{Spark Core}-а \cite{spark_rdd_transf}. Поред поменутих, постоје и \textit{aggregate}, \textit{union}, \textit{intersect}, \textit{mapValues}, \textit{sortByKey} али и многе друге.

\subsection{Акције}
\label{subsec:spark_akc}

\textit{Spark}-акције се користе када је потребно евалуирати резултат ланца трансформација \cite{spark_guide}. Уколико је резултат акције нека вредност, она се прослеђује контролном процесу. Постоје три врсте акција:

\begin{itemize}
\item акције које приказују резултат у конзоли;
\item акције које исписују резултат на излаз, на пример у фајл;
\item акције које пребацују податке у колекцију програмског језика у коме се користи \textit{Spark}.
\end{itemize}

Као и трансформације, \textit{RDD}-акције су део \textit{Spark Core}-а  \cite{spark_rdd_transf}. Неке од најкоришћенијих акција су:

\begin{itemize}
	\item \textbf{\textit{count}}, исписује број елемената у структури података;
	\item \textbf{\textit{saveAsTextFile}}, чува податке унутар \textit{RDD}-ја у текстуални фајл;
	\item \textbf{\textit{collect}}, пребације све податке \textit{RDD}-ја у колекцију програмског језика;
	\item \textbf{\textit{take}}, пребацује првих \textit{N} података \textit{RDD}-ја у колекцију програмског језика.
\end{itemize}

\subsection{Руковање грешкама}
\label{subsec:spark_dags}

У току извршавања \textit{Spark}-трансформација могућа је појава грешака које могу да резултују губитком партиција. У том случају је \textit{Spark} у могућности да их поврати помоћу механизма који се назива граф наслеђивања (енг. \textit{lineage graph}) у коме се чувају информације о томе од ког \textit{RDD}-ја је сваки \textit{RDD} у ланцу трансформација настао и применом којих трансформација. Пример једног ланца \textit{Spark}-трансформација који у исто време представља и граф наслеђивања је приказан на  слици \ref{fig:sprk_ppln}. Из примера се може закључити да је \textit{RDD\_5} настао спајањем \textit{RDD\_2} и \textit{RDD\_4}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.9\textwidth]{pictures/spark_ppln.png}
  \caption{Пример једног \textit{Spark}-извршавања}
  \label{fig:sprk_ppln}
\end{figure}

Уз помоћ графа наслеђивања \textit{Spark} може да закључи од које партиције је настала свака партиција у ланцу и уколико нека од њих нестане, може је поново направити \cite{hadoop_learning}. У случају да нека партиција ланца није исправна, \textit{Spark} ће проверити све партиције од којих је она настала. Уколико оне постоје, поново ће направити неисправну партицију од њих, примењујући потребне трансформације. У супротном ће рекурзивно прегледати изворне партиције тих партиција и тај процес ће понављати све док се не пронађе исправна партиција или се не дође до партиције која је настала директним читањем са диска. У том случају ће је \textit{Spark} поново прочитати и након тога покренути ланац трансформација из почетка.

Процес поновне конструкције партиција је поуздан из два разлога. Први је што трансформације немају бочне ефекте, па ће се поновним креирањем увек добити одговарајући \textit{RDD}. Други је што се изворни подаци чувају у \textit{HDFS}-у, који је поуздан, па ће се у случају поновног читања из меморије и поновним креирањем читавог ланца, увек прочитати почетна, непромењена, вредност са диска.

\subsection{Кеширање}
\label{subsec:spark_persist}

Веома битна карактеристика \textit{Spark}-а је могућност чувања података у меморији, односно кеширање \cite{spark_rdd}. Када се \textit{RDD} кешира, свака машина у кластеру ће у својој меморији сачувати партиције које се на њој налазе и касније их користити у акцијама или трансформацијама у којима је тај \textit{RDD} потребан, без извршавања целог ланца трансформација из почетка. Овакав приступ знатно побољшава перформансе \textit{Spark}-апликације. Чување у меморији се извршава тек након што \textit{RDD} учествује у некој акцији. Кеширање је отпорно на грешке, и за поновно креирање несталих партиција кешираног \textit{RDD}-ја се користи граф наслеђивања.

\textit{RDD} се може кеширати коришћењем функција \textit{cache} и \textit{persist} \cite{spark_rdd}. Оне омогућавају различите нивое кеширања у зависности од тога у којој врсти меморије се партиције чувају:

\begin{itemize}
	\item \textit{cache} кешира податке у меморији;

	\item \textit{persist} са аргументом \textit{MEMORY\_ONLY} кешира податке у меморији;

	\item \textit{persist} са аргументом \textit{DISC\_ONLY} кешира податке на диску (овај приступ се не саветује зато што је често брже поново извршити цео ланац трансформација из почетка, него учитати кеширан \textit{RDD} са диска);

	\item \textit{persist} са аргументом \textit{MEMORY\_ONLY\_2} кешира податке у меморији али поред тога извршава репликацију \textit{RDD}-ја на још једну машину кластера;

	\item \textit{persist} са аргументом \textit{DISC\_ONLY\_2} кешира податке на диску али поред тога извршава репликацију \textit{RDD}-ја на још једну машину кластера;

	\item \textit{persist} са аргументом \textit{MEMORY\_AND\_DISC} кешира податке у меморији уколико постоји довољно простора, а у супротном кеширање извршава на диску.
\end{itemize}

\section{Апстракција података \textit{DataFrame}}
\label{sec:spark_df}

\textit{DataFrame} је дистрибуирана колекција налик табели, са дефинисаним редовима и колонама \cite{spark_guide}. Свака колона мора имати исти број редова и сваки ред мора имати исти број колона. Поред тога, свакој колони је додељен један тип ког морају бити све вредности које се у њој налазе.
% иако  можемо користити недостајуће вредности за број колона у редовима

Сваки \textit{Spark DataFrame} садржи метаподатке који описују имена колона и њихове типове  \cite{spark_guide}. Ти метаподаци се називају шема (енг. \textit{schema}). Шема се може дефинисати експлицитно али се може и аутоматски закључити из података који се налазе унутар \textit{DataFrame}-а. Поред типова, у шеми се налази информација о томе да ли колона може поседовати вредности \textit{null}. На слици \ref{fig:sprk_df_schema_example} је приказан једноставан пример \textit{DataFrame}-а и његове шеме.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1\textwidth]{pictures/dataframe_schema.png}
  \caption{\textit{Spark DataFrame} и његова шема}
  \label{fig:sprk_df_schema_example}
\end{figure}

У \textit{Spark}-у постоји велики број типова који се могу доделити колонама \textit{DataFrame}-а \cite{spark_guide}. Постоје једноставни типови попут целих бројева, децималних бројева и ниски али постоје и сложени, попут низова, мапа и датума. Сви \textit{Spark}-типови се могу пресликати у одговарајуће типове програмских језика у којима се он користи.

\subsection{Трансформације и акције \textit{DataFrame}-а}
\label{subsec:spark_sql_ac_tr}

Све особине трансформација и акција које важе за апстракцију \textit{RDD}, важе и за трансформације и акције \textit{DataFrame}-а \cite{spark_guide}. Дакле, трансформације немају бочне ефекте и лењо се евалуирају, тек када се позове акција. Такође, резултат трансформације примењене на \textit{DataFrame} ће увек бити нови \textit{DataFrame}. Једина разлика је у томе што \textit{RDD} и \textit{DataFrame} другачије представљају податке, па су им трансформације и акције другачије. Како је \textit{DataFrame} сличан табели у релационим базама, поседује неколико трансформација које су аналогне наредбама у програмском језику \textit{SQL}. Неке од најкоришћенијих \textit{DataFrame}-трансформација су приказане на слици \ref{fig:sprk_df_trnsf_example} и то су:

\begin{itemize} 
	\item \textbf{\textit{select}}, конструише нови \textit{DataFrame} са подскупом колона почетног;
	\item \textbf{\textit{filter}}, конструише нови \textit{DataFrame} са редовима почетног који задовољавају задати услов;
	\item \textbf{\textit{withColumn}}, конструише нови \textit{DataFrame} додавањем колоне на почетни -- вредности нове колоне се генеришу функцијом која је прослеђена као аргумент овој трансформацији;
	\item \textbf{\textit{join}}, спаја два \textit{DataFrame}-а у један на основу заједничких вредности колона.
\end{itemize}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1\textwidth]{pictures/df_trnsf_example.png}
  \caption{Примери \textit{DataFrame}-трансформација}
  \label{fig:sprk_df_trnsf_example}
\end{figure}

Примери акција \textit{DataFrame}-а су \textit{collect}, која трансформише \textit{DataFrame} у структуру података програмског језика у коме се \textit{Spark} користи и \textit{show}, која се користи за испис \textit{DataFrame}-а на стандардни излаз \cite{spark_guide}. Поред њих постоје и многе друге.

\subsection{Кориснички дефинисане функције}
\label{subsec:spark_udf_section}

Одређене трансформације као аргумент примају функцију коју користе да би добиле резултате. Једна таква трансформацијa је \textit{withColumn} која генерише нову колону у односу на повратну вредност функције која јој се прослеђује. \textit{Spark} садржи велики број уграђених функција које се могу користити и оне се налазе унутар \textit{org.apache.spark.sql.functions} модула \cite{spark_builtin_func}. Уколико је потребно користити функционалност коју \textit{Spark} нема уграђену, може се користити кориснички дефинисина функција (енг. \textit{user defined function}), скраћено \textit{udf}.

\textit{Udf} је функција написана у Скали која је регистрoвана од стране \textit{Spark}-а наредбом \textit{udf}, којој се прослеђују Скала-функција, повратни тип и типови аргумената функције. Пример креирања \textit{udf}-а и његовог коришћења у трансформацији \textit{withColumn} је приказан у коду \ref{lst:spark_udf_usage_example}.

\begin{lstlisting}[caption={Пример коришћења \textit{udf}-а}, language=Scala, label={lst:spark_udf_usage_example}]
val someFunction: (arg_type1, arg_type2) => ret_type_1 = (x: arg_type_1, y: arg_type_2) => {
  // function body
}

val udfRegistered = udf[ret_type_1, arg_type_1, arg_type_2](someFunction)

someDataFrame
  .withColumn("col_name", udfRegistered(arg1, arg2)) 
\end{lstlisting}

Честo се дешава да конструисан \textit{udf} користи променљиве које су креиране ван његовог тела, као у коду \ref{lst:spark_udf_broadcast_no}. Овакав приступ није добра пракса због тога што ће се низ \textit{a} слати извршиоцима сваки пут када се ова операција иницира, што може знатно успорити извршавање.

\begin{lstlisting}[caption={Пример коришћења променљиве дефинисане ван тела \textit{udf}-а}, language=Scala, label={lst:spark_udf_broadcast_no}]
val a: Array[Int] = Array(1, 2, 3, 4, 5)

val checkFunc: (Int) => Boolean = (x: Int) => {
  a.contains(x)
}

val udfRegistered = udf[Boolean, Int](checkFunc)
\end{lstlisting}

Да би се избегло слање података сваки пут, могу се користити променљиве \textit{broadcast} \cite{spark_broadcast}. Оне се кеширају у извршиоцима и увек су доступне, чиме се избегава беспотребно слање података. Променљиве \textit{broadcast} се креирају наредбом \textit{broadcast}, објекта \textit{SparkContext} и њиховој вредности се приступа преко кључне речи \textit{value}. Ове променљиве се могу користити само за читање података. У коду  \ref{lst:spark_udf_broadcast_yes} се налази измењен к\^{о}д \ref{lst:spark_udf_broadcast_no} тако да користи \textit{broadcast}-променљиву.

\begin{lstlisting}[caption={Пример коришћења променљиве \textit{broadcast}}, language=Scala, label={lst:spark_udf_broadcast_yes}]
val a: Array[Int] = spark.sparkContext.broadcast(
  Array(1, 2, 3, 4, 5)
)

val checkFunc: (Int) => Boolean = (x: Int) => {
  a.value.contains(x)
}

val udfRegistered = udf[Boolean, Int](checkFunc)
\end{lstlisting}

\subsection{Разлика између \textit{DataFrame}-а и \textit{RDD}-ја}
\label{subsec:spark_df_vs_rdd}

Поред различитог начина представљања података, постоји знатна разлика у перформансама између \textit{RDD}-ја и \textit{DataFrame}-а \cite{spark_guide}. \textit{RDD} се користи за програмирање ниског нивоа, пошто омогућава директан рад са партицијама. Међутим, приликом писања \textit{RDD}-трансформација, програмер мора бити веома пажљив када и коју трансформацију примењује, због тога што редослед може значајно да утиче на перформансе.

Са друге стране, редослед примене трансформација \textit{DataFrame}-а не утиче на брзину извршавања \cite{spark_guide}. Разлог томе је што сваки \textit{DataFrame} к\^{о}д пролази кроз аутоматски процес оптимизације, па ће добијени резултат увек бити најбржи могући. За оптимизацију је задужен процес који се зове \textit{Catalyst}. Због перформанси, али и због једноставнијег интерфејса, \textit{DataFrame} је скоро потпуно потиснуо \textit{RDD} из употребе.

\subsection{Планови извршавања \textit{DataFrame}-а}
\label{subsec:spark_exec_plans}

%Процес извршавања \textit{DataFrame}-a се састоји из следећих корака:
%\begin{enumerate}
%\item К\^{o}д \textit{DataFrame}-а је написан
%\item уколико је исправан, од њега се прави логички план
%\item Од логичког плана се конструише физички план, уз примену оптимизација
%\item Добијени физички план се пребацује у \textit{RDD} и извршава се
%\end{enumerate}

Сваки \textit{DataFrame} се приликом покретања прво преводи у \textit{RDD}, након чега се извршава. Добијени \textit{RDD} к\^{о}д ће увек имати оптимизован редослед примена трансформација. Да би се оптимизација успешно изршила, \textit{Spark} током превођења генерише неколико планова извршавања.

Први план који се конструише од \textit{DataFrame} кода је неразрешен логички план (енг. \textit{unresolved logical plan}). Он представља трансформације које треба извршити над \textit{DataFrame}-ом, али не садржи никакве информације о томе над којим колононама, као ни о томе где се подаци које \textit{DataFrame} представља физички налазе \cite{spark_guide}. Те информације се добијају уз помоћ каталога (енг. \textit{catalog}) у коме се налазе информације о \textit{DataFrame}-овима. Резултат примене каталога на неразрешен логички план је логички план (енг. \textit{logical plan}). Анализом логичког плана и применом правила оптимизације на њега, оптимизатор \textit{Catalyst} конструише оптимизован логички план (енг. \textit{optimized logical plan}).

%Једно од правила \textbf{КАТАЛИСТА} се зове \textit{filter pushdown}. Његова улога је да \textit{filter} трансформације узврши што је раније могуће. На пример, у случају да \textit{DataFrame} чита податке из базе и након тога примењује \textit{filter}, долази до читања непотребих података. 

%\begin{figure}[!ht]
%  \centering
%  \includegraphics[width=1\textwidth]{pictures/filter_pushdown.png}
%  \caption{\textit{Filter pushdown}}
%  \label{fig:sprk_ex_plns}
%\end{figure}

Након што се оптимизовани логички план успешно креира, \textit{Spark} у односу на њега конструише неколико физичких планова (енг. \textit{physical plan}) \cite{spark_guide}. Физички план дефинише на који начин и уз помоћ којих наредби ће се логички план извршити на кластеру. Сви физички планови се након тога евалуирају и бира се онај са најбољим перформансама. Он се преводи у \textit{RDD}-трансформације и ивршава на кластеру. Цео процес је приказан на слици \ref{fig:sprk_ex_plns}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.85\textwidth]{pictures/dataframe_optimization.png}
  \caption{Ток извршавања \textit{DataFrame}-a}
  \label{fig:sprk_ex_plns}
\end{figure}

\subsection{Измена броја партиција}
\label{subsec:spark_repartition}

За сваку апстракцију података, \textit{Spark} иницијално креира одређен број партиција које она садржи. На пример, уколико се \textit{DataFrame} креира читањем фајла, број партиција ће бити одређен или бројем партиција у фајлу, уколико фајл формат садржи такву информацију, или параметром \textit{Spark}-конфигурације \textit{spark.files.maxPartitionBytes} \cite{spark_conf}, који одређује максималну величину партиције. Подразумевана вредност параметра је 128\textit{MB}. Поред тога, параметар \textit{spark.default.parallelism} \cite{spark_conf} одређује колико партиција ће имати апстракција која је резултат \textit{join} или трансформација \textit{reduceByKey}. \textit{DataFrame} који настаје од \textit{RDD}-ја позивом функције  \textit{spark.createDataFrame} чији су аргументи \textit{RDD} и шема, ће имати исти број партиција као \textit{RDD} од ког настаје.

Број постојећих партиција је битан због тога што се у једном тренутку, на једном извршиоцу, обрађује тачно једна партиција. Уколико је број партиција мањи од броја извршилаца, постојаће извршиоци који неће обрађивати податке, што значи да искоришћеност кластера није добра. Уколико је број партиција велики, извршавање ће се успорити због тежег распоређивања \textit{Spark}-задатака. Такође, операције \textit{shuffle} постају доста скупље. 

Из наведених разлога постоје трансформације које мењају број партиција. Те трансформације су \textit{repartition} и \textit{coalesce}. Друга се користи само у случају када је потребно смањити број партиција. Предност ове трансформације је избегавање операције \textit{shuffle}, али не гарантује да ће подаци бити подељени подједнако. Са друге стране, \textit{repartition} ће увек применити \textit{shuffle} али податке по партицијама распоређује подједнако. \textit{Repartition} може поделити податке на два начина. Први је прослеђивањем жељеног броја партиција, а други је навођењем жељене колоне \textit{DataFrame}-а по чијим вредностима се извршава партиционисање.

Поред њих, постоји и партиционисање фајла приликом уписа. Извршава се функцијом \textit{partitionBy} којој се наводе колоне по којима се извршава партиционисање. Фајл настао на овај начин групише редове које имају исте вредности у колонама по којима се врши партиционисање у заједничке поддиректоријуме. На пример, уколико \textit{DataFrame} садржи колоне које представљају годину и месец, назване редом \textit{year} и \textit{month} и остале колоне назване \textit{data}, приликом партиционисања при уписивању преко колона \textit{year} и \textit{month} ће настати фајл структура приказана у коду \ref{lst:spark_example_partitionBy_year_month}. Имена и вредности колона по којима се извршава партиционисање се налазе у називима поддиректоријума, док се подаци колона \textit{data} налазе у крајњим фајловима.

\begin{lstlisting}[caption={Пример структуре излазног директоријума који настаје партиционисањем}, language=Scala, label={lst:spark_example_partitionBy_year_month}]
|-- year=2022
|   |-- month=12
|   |   |-- part-00000-file-name.format
|   |   |-- part-00001-file-name.format
|   |-- month=11
|   |   |-- part-00000-file-name.format
|   |   |-- part-00001-file-name.format
|   |-- month=etc
|   |   |--etc
|-- year=2021
|   |-- month=12
|   |   |-- part-00000-file-name.format
|   |   |-- part-00001-file-name.format
|   |-- month=11
|   |   |-- part-00000-file-name.format
|   |   |-- part-00001-file-name.format
|   |-- month=etc
|   |   |--etc
|-- year=etc
\end{lstlisting}

\section{Остале компоненте \textit{Spark}-а}
\label{sec:spark_components}

\textit{Spark} омогућава коришћење \textit{SQL}-упита над подацима. Сваки \textit{Spark SQL}-упит пролази кроз исти процес оптимизације као и \textit{DataFrame} \cite{spark_guide}. Једина разлика је у томе што се синтаксне грешке \textit{SQL} кода појављују током извршавања програма, док се синтаксне грешке \textit{DataFrame} кода појављују приликом компајлирања. У коду \ref{lst:sprk_sql_df_slct_example} је приказано када долази до појаве грешке приликом покретања еквивалентних \textit{DataFrame} и \textit{SQL} наредби са погрешно написаном речи \textit{select}.  

\begin{lstlisting}[language=Python, caption={Извршавање \textit{DataFrame} и  \textit{SQL} кодова са грешком у писању}, label={lst:sprk_sql_df_slct_example}]
# Spark DataFrame
dataframe.slect()
>>> compilation error

# Spark SQL
spark.sql('slect * from dataframe')
>>> runtime error
\end{lstlisting}

Поред апстракција података \textit{RDD} и \textit{DataFrame}, постоји и \textit{DataSet}, који је доступан само у језицима заснованим на Јавиној виртуелној машини, Скали и Јави \cite{spark_guide}. Представља податке на исти начин као \textit{DataFrame} и пролази кроз исти процес оптимизације. Разлика је у провери типова вредности унутар колона, која се код \textit{DataFrame}-а дешава током извршавања програма, док се код \textit{DataSet}-а провера типова ради за време компајлирања.

Уз помоћ \textit{Spark}-а се могу конструисати модели машинског учења, преко библиотеке \textit{Spark MLlib} \cite{spark_guide}. Она се може користити за препроцесирање, тренирање модела и прављење предвиђања. \textit{Spark} поседује и библиотеку за рад са графовима, \textit{GraphX}, али се због њених разних недостатака, за обраду графова на кластеру често користе друга решења.

\textit{Spark} се може користити и за операције над токовима података \cite{spark_streaming}. \textit{Spark streaming} омогућава претплату на токове који настају из веб сокета (енг. \textit{web socket}), локације у фајл систему или од стране \textit{Apache Kafka}-е. Након претплате, на податке у току се могу примењивати исте трансформације као код \textit{DataFrame}-а.

% ако хоћеш да причаш о каталисту можеш наћи овде https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html

% -------------------------------------
\begin{comment} % -------------------------------------
% -------------------------------------

\chapter{Семантички веб}
\label{chp:sem_veb}

Веб је током свог постојања константно еволуирао. Разликују се три веће етапе које су назване по редним бројевима, Веб 1.0, Веб 2.0 и Веб 3.0.

\section{Веб 1.0}
\label{sec:sem_veb_veb_1}

Ова верзија представља прву фазу еволуције веба. Настао је у последњим деценијама 20. века и трајао је до средине прве деценије 21. Карактерише га скуп статичког садржаја који је повезан преко веза названих \textit{hyperlik}.

Уз помоћ њега су представљане само информације које су се приказивале корисницима. Још увек није постојао језик за улепшавање страница, \textit{CSS} и није било динамичких линкова, логовања корисника и остављања коментара.

%Веб страница Свемирског баскета (енг. \textit{Space Jam}), популарног филма из 90-тих нам даје увид у то како је изгледала једна страница тада, пошто је непромењена од тренутка када је направљена, 1996. године. Можемо је пронаћи на адреси https://www.spacejam.com/1996/.

%\begin{figure}[!ht]
%  \centering
%  \includegraphics[width=1\textwidth]{pictures/space_jam.png}
%  \caption{Веб страница Свемирског баскета}
%  \label{fig:sem_veb_space_jam}
%\end{figure}

\section{Веб 2.0}
\label{sec:sem_veb_veb_2}

Друга фаза је почела одмах након прве и траје и дан данас. Акценат је стављен на садржај генерисан од стране корисника, једноставно коришћење као и на размени информација. У овој фази је, преко програмских језика који се извршавају на серверској страни, омогућен рад разних апликација попут Амазона (енг. \textit{Amazon}), Ју Тјуба (енг. \textit{YouTube}) и Фејсбука (енг. \textit{Facebook}). Све то је омогућило корисницима да на једноставан начин деле и размењују своја мишљења и искуства.

%\begin{figure}[!ht]
%  \centering
%  \includegraphics[width=1\textwidth]{pictures/youtube_page.png}
%  \caption{YouTube веб страница}
%  \label{fig:sem_veb_you_tube_page}
%\end{figure}

Међутим, Веб 2.0 има једну велику ману, а то је да се сви подаци, које поменуте апликације сакупљају, складиште на приватним серверима које контролишу корпорације. Велики број њих користи те податке да би кориснике што дуже задржалo на својим сервисима. Такође, у неколико инстанци су ти подаци продавани некој другој страни, у циљу једноставне зараде. Због овога се може рећи да су корисници постали производ друге фазе веба.

\section{Веб 3.0}
\label{sec:sem_veb_veb_3}

Циљ треће верзије веба је да се ослободи централизације присутне у вебу 2.0 и направи децентрализован али сигуран интернет где би људи могли да размењују информације без посредника, ког тренутно представља корпорација чије услуге ти корисници користе.

Последица децентрализације је та да апликације више неће бити покретане преко огромних, приватних, база података и сервера, већ ће се прећи на технологије као што су блокчеин (енг. \textit{blockchain}) и мреже равноправних корисника (енг. \textit{peer-to-peer}).

Идеја је да у самом срцу веба 3.0 стоји семантички веб, чија би улога била да повеже постојеће податке и информације које се налазе на интернету, и направи их таквим да њихов садржај и контекст могу разумети машине.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1\textwidth]{pictures/webs_vrs.jpg}
  \caption{Фазе Веба}
  \label{fig:sem_veb_versions}
\end{figure}

Ова верзија Веба је још увек у развоју, са огромним простором за даље истраживање. Међутим, како је сама архитектура доста комплекснија од архитектуре Веба 2.0, није сигурно да ли ће заживети и ако да, када. Али оно што је сигурно је да идеја о дељеним подацима и децентализованом вебу и даље постоји и велики број људи је развија и унапређује.

%Један од примера веб 3.0 апликације је \textit{odysee} направљена за дељење видео снимака и сматра се децентрализованом алтернативом \textit{YouTube}-a. Ова апликација користи \textit{LBRY} протокол \cite{lbry} који је базиран на блокчеин технологији и користи се за дељење фајлова и плаћање. \cite{odysee_article}

%Тим који стоји иза ове апликације сматра да је \textit{YouTube} превише стриктан у томе који садржај бира да промовише и блокира. \textit{Odysee} je настала са идејом слободе говора и направљена је тако да је свако може користити да промовише своје погледе на свет. \cite{odysee_article}

%Идеја иза веба 3.0 је таква да интернет више не контролишу компаније које поседију сервере, већ да се та контрола пребаци на кориснике. Самим тим, информације о корисницима се више неће налазити на приватним серверима, већ ће бити пребачене код самих корисника, уз помоћ блокчеин технологије.  \cite{coinbase_web3}

%То доводи до огрмоних промена у томе како веб функционише. Архитектура веба 2.0 је једноставна. Састоји се од клијента, који је обично представљен интернет претраживачем или неком апликацијом, који комуницирају са серверима и од њих добијају информације уз помоћ којих функционишу. Ентитет који контролише сервере, контролише и који корисници могу да им приступају као и шта они могу да виде, па стога, један корисник може имати привилегован статус у односу на другог. Поред тога, чува информације о поменутим корисницима и о томе шта они на тим серверима поседују. \cite{coinbase_web3}

%У вебу 3.0, апликацијама је дозвољено да чувају садржај на јавно доступном блокчеину. Дакле, тај садржај постаје доступан свима. Такође, дозвољава корисницима директну контролу над тим садржајем. Идеја је да не постоји потреба за корисничким налозима или привилегованим АПИ (енг. \textit{API}) кључевима, већ да свако може да приступи свему. 

%Веб 3.0 то омогућава уз помоћ употребе крипто новчаника (енг. \textit{crypto wallet}), уз помоћ ког наша апликација шаље трансакције на блокчеин, и блокчеин чворова (енг. \textit{blockchain node}), чија је улога да надгледају и регистрију трансакције које се дешавају на блокчеину. \cite{coinbase_web3}

%Када крипто новчаник жели да пошаље неку трансакцију на блокчеин или када од њега захтева некакве информације, комуницираће са блокчеин чворовима. Преко тога је нашој апликацији омогућено да комунуцира са блокчеином и на тај начин она сакупља информације које су јој потребне да би правилно функционисала. Овај однос подсећа на однос који данашње апликације имају са својим приватним серверима. \cite{coinbase_web3}

%Поређење архитекура између две верзије веба је приказано на слици \ref{fig:sem_veb_veb3_arh}.

% https://www.coinbase.com/learn/crypto-basics/what-is-a-crypto-wallet

%\begin{figure}[!ht]
%  \centering
%  \includegraphics[width=1\textwidth]{pictures/veb3_arh.png}
%  \caption{Једноставан приказ архитектура веба 2.0 и веба 3.0}
%  \label{fig:sem_veb_veb3_arh}
%\end{figure}

%Наравно, веб 3.0 доноси и неколико проблема. Прво, тренутне машине које се користе за рударење криптовалута и праћење трансакција конзумирају огромне количине енергије, па ће стога њена потрошња бити велики проблем који се мора решити пре него што веб 3.0 постане стварност.

%Такође, сви подаци ће се и даље налазити на серверима али ти сервери неће бити у приватном власништву великих корпорација. То доноси неколико питања. На пример, ко је власник тих сервера? Ко плаћа нихово одржавање? Ко има информације о нашим налозима, попут шифри које користимо и других личних података? Дакле, неко ће ипак бити власник наших података, с тим што се поставља питање, ко тачно?

% https://www.stephendiehl.com/blog/web3-bullshit.html

%Ова верзија веба је још увек нова, са огромним простором за даље истраживање али се због свега наведеног није сигурно да ли ће икада заживети, и ако да, када? Оно што је сигурно да идеја о дељеним подацима и децентализованом вебу и даље постоји и велики број људи је развија и унапређује. У самом средишту дељења података се налази семантички веб.

\section{Семантички веб}
\label{sec:semantic_veb_main}

Семантички веб је надоградња садашњег веба, \textit{WWW}-а, који омогућава рачунарима да, на интелигентан начин, претражују и обрађују податке са веба. Интелигентно у овом случају значи да ће рачунари бити способни да закључе шта подаци представљају људима који их користе. Пошто до сада није конструисан ниједан систем вештачке интелигенције који може потпуно да опонаша човека, то се може постићи само ако се значење, то јест семантика, ресурса на вебу експлицитно представи рачунарима у формату у којем их они могу обрадити. \cite{semantic}

Да би се ово постигло, није довољно само складиштити податке у језику који машине разумеју, на пример у \textit{HTML} формату, већ је неопходно да се уз те податке додају и информације о семантици која јасно говори које закључке треба из њих извући. Међутим, тако нешто је врло вероватно немогуће извести због тога што је чак и људима тешко да се договоре око значења садржаја одређених страница на вебу, па је стога још теже формализовати тај садржај на такав начин да буде значајан машинама. \cite{semantic}

%Дакле, семантички веб заправо има намену да омогући машинама приступ већем броју информација, којима је до сада приступао само човек, у на тај начин доведе до смањења потрошње времена корисника интернета.
%То значи да семантички веб заправо има другу намену, а то је омогући машинама приступ  већем броју информација којима тренутно приступа човек, што доводи до смањења потрошње времена. То значи да семантички веб заправо није екстензија данашњег веба, већ некакав идеал ка коме веб временом еволуира. \cite{semantic}

Да би семантички веб функционисао, на неки начин се људско знање мора изразити неким формалним језиком. Тај проблем се може решити моделовањем. Један од језика који се користи у семантичком вебу је \textit{OWL 2} и настао је под утицајем коришћења моделовања у биологији. На који начин ће знање бити моделовано зависи од тога за шта ће конструисан модел бити коришћен. Код семантичког веба, идеја је да компјутерски програми закључују на основу датих информација на такав начин да узимају у обзир резоновање и формалну репрезентацију знања. \cite{semantic}

Дакле, развој семантичког веба се заснива на припајању моделовања знања и аутоматског закључивања вебу. Исто тако, на овај начин се веб апликације уводе у домен формалног моделовања и репрезентације знања. 

Иако су раније постојали примери стандардизације саме формалне репрезентације знања, семантички веб је допринео њеној важности и употребљивости. Велика већина релевантних покушаја стандардизације је спроведена од стране \textit{WWW} Конзорцијума, познатијег као \textit{W3C}. \cite{semantic}

%Исто тако, сам Веб у друге дисциплине уводи појам дистрибуираних али повезаних информација. Веб ставља акценат на важност јасно дефинисаних, стандардизованих језика који се користе за размену података између различитих јединица. 

\subsubsection{Историјат}
\label{subsubsec:semantic_timeline}

Идеја додељивања семантике вебу није нова и постојала је још у самом зачећу веба. Први покушаји су забележени код типизираних линкова (енг. \textit{typed links}) чија је улога била да, поред тога што су представљали референцу ка другом документу, садрже и неке информације о томе шта заправо тај линк представља. \cite{semantic}

Семантички веб је добио већу пажњу јавности 2001. године, када је Тим Бернерс Ли (енг. \textit{Tim Berners-Lee}) објавио чланак назван \textit{Семантички веб} у којем су представљене идеје о томе како би семантички веб функционисао. До данас је \textit{W3C}, чији је Тим Бернерс Ли члан, објавио неколико технологија међу којима су \textit{RDF, Resоurce Description Framework}, \textit{OWL, Web Ontology Language} и језик за упите \textit{SPARKQL}, али и многе друге. \cite{semantic}

Поред тога су забележени и покушаји у томе да се у \textit{HTML} документе, преко вредности атрибута, доделе неки семантички подаци једном веб документу. Те вредности се називају микроформати (енг. \textit{microformats}) и користе се за решавање проблема у специфичним доменима апликација, на пример, приликом енкодирања личних података. \cite{semantic}

Једноставан пример микроформата је \textit{HTML} атрибут \textit{rel} који се користи да би се назначило шта се налази на линку коме тај атрибут је додељен. У следећем примеру се користи да би се нагласило да се на приложеном линку налази лиценца.

\begin{lstlisting}[language=HTML]
<small>This article is licensed under a 
  <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/2.0/">
  Creative Commons Attribution Non-commercial Share-alike 
  (By-<abbr>NC</abbr>-<abbr>SA</abbr>) license</a>.
</small>
\end{lstlisting}

Количина семантичких података која је доступна на вебу се повећава из године у годину и подаци су постали међусобно повезани. Ово се дешава због тога што идентификатори који се користе у језицима семантичког веба прате исте принципе као и адресе класичног веба. Стога, име једног објекта семантичког веба се може интерпретирати као веб адреса. То доводи до појаве повезаних података (енг. \textit{linked data}) која се односи на семантичке податке чији су идентификатори заправо показивачи ка веб адресама на којима се може пронаћи више информација о објекту. \cite{semantic}

Због тога се користи термин \textit{веб података}, који описује семантички веб као покушај који се примарно фокусира на размену података. 

\subsection{RDF језик}
\label{subsec:semantic_rdf}

Механизам за описивање ресурса (енг. \textit{resource description framework}) или скраћено \textit{RDF} је формални језик за описивање структуираних информација. Поента овог језика је да омогући апликацијама да размењују податке на вебу задржавајући њихово оригинално значење. За разлику од језика као што су \textit{HTML} и \textit{XML}, циљ није приказати документе у правилном формату већ омогућити обраду информација које они садрже. Због свега наведеног \textit{RDF} се често сматра основом за развој семантичког веба. \cite{semantic}

Дакле, улога \textit{RDF}-а није да описује структуру докумената, већ да опише однос између неких објеката. Данас је овај формат веома распростањен и готово сваки виши програмски језик поседује библиотеке помоћу којих се могу извршавати разне операције над њим. \cite{semantic}
 
\textit{RDF} документ је описан усмереним графом, односно скупом чворова који су повезани усмереним гранама. Сваки чвор и свака грана имају засебан идентификатор. Структура графа је изабрана баш из тог разлога да би се изразио однос између објеката, а не њихова хијерархија. На пример, на слици \ref{fig:semantic_rdf_graph_example} се примећује да је однос између приказаних елемената, курса и студената, информација која нема јасну хијерахију. \textit{RDF} користи такав однос као основну јединицу информације. Штавише, велики број таквих односа производи графове. \cite{semantic}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.8\textwidth]{pictures/rdf_graph_example.png}
  \caption{Пример РДФ графа}
  \label{fig:semantic_rdf_graph_example}
\end{figure}

Други разлог због кога је \textit{RDF} представљен графом је чињеница да му је улога да служи као описни језик података веба и других мрежа. Иформације у овим срединама се складиште и обрађују дистрибуирано па је стога битно комбиновати \textit{RDF} податке на једноставан начин. На пример, граф који је репрезентација једних података се лако може повезати са графом који представља нешто друго, једноставним повезивањем. Ако претпоставимо да поред графа на слици \ref{fig:semantic_rdf_graph_example} постоји, на пример, још један граф који описује студенте, лако се може закључити да се они једноставно могу повезати и користити заједно. \cite{semantic}

Додељивање имена \textit{RDF} документима може произвести проблеме. Наиме, именовање не мора бити униформно. На пример, могуће је да два документа садрже информације о истој теми, али да су им идентификатори потпуно различити. Такође, могуће је и да је једном истом ресурсу додељено неколико различитих имена или да се исти идентификатори користе за различите појмове.

Да би се тај проблем избегао \textit{RDF} користи униформни индикатор ресурса (енг. \textit{uniform resource identificator, URI}) као имена, у циљу разликовања ресурса. Напоменимо да је \textit{URI} генерализација \textit{URL} адреса које се користе за приступ документима на интернету. Како је сваки \textit{URL} валидан \textit{URI}, може се користити као идентификатор унутар \textit{RDF} докумената. У великом броју апликација циљ није разменити информације о веб страницама већ о великом броју објеката као што су на пример студенти, књиге, места, догађаји и тако даље. Таквим објектима се не може приступити на интернету па се њихов \textit{URI} користи ускључиво за идентификацију. Напоменимо и то да се \textit{URI} адресе које нису \textit{URL} називају \textit{URN}. \cite{semantic}

Због идентификације, чворовима и гранама унутар \textit{RDF} графа се додељује \textit{URI} као име, што можемо приметити и на већ приложеном примеру (слика \ref{fig:semantic_rdf_graph_example}). Ово правило има два изузетка. Први је тај да је ипак могуће доделити име које није \textit{URI}, а други је да је могуће не доделити име и оставити га празним, али се таквим случајевима нећемо бавити. \cite{semantic}

Иако \textit{URI} представљају имена, њихово значење је подложно интерпретацији па другачији алати могу на другачији начин да посматрају њихово значење. Због тога је уведен још један појам, литерал, који представља вредности унутар \textit{RDF}-а. Увек су записани ниском уз коју је припојен и њен тип. На пример, ниска \textit{"123"} може бити целобројног типа што би значило да представља број \textit{123}. За разлику од \textit{URI}-ја, литерали увек имају једно значење. У графу се представљају правоугаоним чворвима (слика \ref{fig:sem_rdf_graph_2})). \cite{semantic}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.8\textwidth]{pictures/rdf_graph_example_2.png}
  \caption{Пример РДФ графа са литералима}
  \label{fig:semantic_rdf_graph_2}
\end{figure}

\subsubsection{Репрезентација}
\label{subsubsec:semantic_rdf_representation}

Како су \textit{RDF} графови ретки, представљају се скупом грана које се у њему налазе. Једна грана је представљена вредношћу чворова, као и њеном ознаком. Чворове називамо субјекат и објекат, док се ознака назива предикатом. Тројка субјекат-предикат-објекат се другачије назива и \textit{RDF} тројком. Сваки члан тројке може бити некакав \textit{URI} али може бити и литерал. \cite{semantic}

Један од формата који се користе за репрезентовање \textit{RDF} графа је корњача (енг. \textit{turtle}) нотација. У овој нотацији се граф са слике \ref{fig:semantic_rdf_graph_2} приказује на следећи начин:

\begin{lstlisting}[language=XML]
<http://semantic-web-book.org/uri> <http://example.org/publishedBy> <http://crcpress.com/uri> .
	
<http://semantic-web-book.org/uri> <http://example.org/title> "Foundations of Semantic Web Technologies" .

<http://crcpress.com/uri> <http://example.org/name> "CRC Press" 
\end{lstlisting}

Међутим, овај запис, тачније \textit{URI} који му припадају, се може скратити увођењем префикса који означавају именска поља која представљају фамилију \textit{URI} адреса. Уз помоћ њих се исти запис може записати доста једноставније:

\begin{lstlisting}[language=XML]
@prefix book: <http://semantic-web-book.org/> .
@prefix ex: <http://example.org/> .
@prefix crc: <http://crcpress.com/> .

book:uri ex:publishedBy crc:uri .
book:uri ex:title "Foundations of Semantic Web Technologies" .
crc:uri ex:name "CRC Press" .
\end{lstlisting}

Поред корњача нотације, чест начин репрезентовања \textit{RDF} структуре је уз помоћ \textit{XML} формата. Разлог томе је што је тај формат читљив и људима и машинама, али и тај што скоро сваки програмиски језик поседује алате за обраду тог формата. Приказ једноставног \textit{RDF} графа са слике \ref{fig:semantic_rdf_graph_2} у \textit{XML} формату се може наћи у наставку:

\begin{lstlisting}[language=XML]
?xml version="1.0" encoding="utf-8"?>
<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"xmlns:ex ="http:/example.org/">
  <rdf:Description rdf:about="http://semantic-web-book.org/uri">
    <ex:publishedBy>
      <rdf:Description rdf:about="http://crcpress.com/uri">
      </rdf:Description>
    </ex:publishedBy>
  </rdf:Description>
</rdf:RDF>
\end{lstlisting}

%РДФ шема, страна 46 у књизи. можда то да додаш (\textit{RDF})

%\textbf{Chapter 7
%Query Languages
%In previous chapters, we learned about a number of possibilities for specifying
%information in a machine-readable way. RDF allows us to structure and relate
%pieces of information, and RDFS and OWL introduced further expressive
%means for describing more complex logical relations. The latter was further
%extended by means of logical rules that could be combined with OWL. For
%each of those description languages, we also introduced a notion of logical
%entailment: RDF(S) documents may entail other documents (Chapter 3),
%and OWL knowledge bases – possibly augmented with rules – can imply new
%axioms (Chapters 4, 5, 6)}


\subsection{OWL}
\label{subsec:semantic_owl}

\textit{OWL}, скраћено од \textit{Web Ontology Language}, је језик семантичког веба који се користи за представљање комплексног знања о стварима, њиховим групама или њиховим релацијама. Комплексно знање у овом контексту су инфомације које се не могу изразити преко \textit{RDF} формата. Овај језик спада у групу логичких језика, па се знање које изражава може користити унутар компјутерских програма. \textit{OWL} документ се назива онтологијом и могуће га је поставити на интернет, одакле га могу реферисати неке друге \textit{OWL} онтолигије. \cite{semantic}

Тренутна верзија овог језика је \textit{OWL 2}. 

%https://www.w3.org/2001/sw/wiki/OWL

\subsection{SPARQL}
\label{subsec:semantic_query}

Иако се информације из претходно поменутих \textit{RDF} и \textit{OWL} формата могу сазнати њиховом обрадом, то често у пракси није довољно. Због тога су настали упитни језици, чија је улога извлачење потребних информација из разних структура података семантичког веба. Упитни језик за \textit{RDF} је назван \textit{SPARKQL}. \cite{semantic}

Спаркл, или \textit{SPARQL}, \textit{SPARQL protocol and RDF query language}, је стандард за упите информација \textit{RDF} формата као и за представљање добијених резултата. Иако је синтакса овог језика веома слична синтакси језика \textit{SQL}, користе се за упите над тотално другачијим структурама података. \cite{semantic}

Пример једног \textit{SPARQL} упита је приказан у наставку.

\begin{lstlisting}[language=XML]
PREFIX ex: <http://example.org/>
SELECT ?title ?author
WHERE { 
	?book   ex:publishedBy   <http://crc-press.com/uri> .
	?book   ex:title         ?title .
	?book   ex:author        ?author 
}
\end{lstlisting}

Приказани упит се састоји из три дела. Први део је одређен са речи  \textit{PREFIX} и означава именски простор, исто као у корњача нотацији. Након њега следи \textit{SELECT} који одређује формат резултата који ће бити приказан. Трећа фаза, у којој се заправо упит и извршава, је означена са \textit{WHERE} коју прати некакав приказ графа. У приказаном примеру је граф представљен са три тројке које означавају која правила морају да важе за информације које упитом желимо да добијемо. У овом случају су то наслови и аутори чланака које је објавио \textit{CRC Press}, таквих да наслов и аутор постоје. \cite{semantic}

Наравно, Спаркл језик је доста мођнији од једноставног примера који је приказан, али улазак у детаље је ван опсега овог рада.

%query languages, chapter 7
%https://www.w3.org/2001/sw/wiki/SPARQL

\subsection{Употреба семантичког веба}
\label{subsec:semantic_end}

Семантички веб је и даље млада технологија која се развија, и тренутно се налази у фази између примене и развоја, али има велики потенцијал и може имати велики број примена. У последње време неке веб странице и портали почињу да користе \textit{RDF} и метаподатке и на тај начин постају део уланчаних података (енг. \textit{linked data}). У последње време се појављују и семантичке википедије, које су сличне као и већ постојеће, с тим што омогућавају кориснику да мења метаподатке који допуњује странице. Поред њих се развијају и семантички портали, веб странице где поред информација доступних човеку, постоје и друге, онтолошке, намењене машинама. Те информације се користе у циљу побољшања искуства корисника који користе те портале. \cite{semantic}

% https://www.w3.org/standards/semanticweb/
% http://people.mpi-inf.mpg.de/~dstepano/KRSW/literature/SWTechnologies.pdf

% -------------------------------------
\end{comment} % -------------------------------------
% -------------------------------------

\chapter{Скуп података \textit{OpenStreetMap}}
\label{chp:osm}

\textit{OpenStreetMap}, скраћено \textit{OSM}, је бесплатна мапа света која дозвољава приступ географским мапама, као и подацима које те мапе садрже \cite{osm_wiki}. Основна идеја овог пројекта је да заједница корисника развија и одржава мапе које представљају алтернативу већ постојећим мапама, попут оних које развија \textit{Google} \cite{google_maps}. Пример мапе \textit{OSM} на вебу је приказан на слици \ref{fig:osm_map_example}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1\textwidth]{pictures/osm_example.png}
  \caption{Приказ Београда у \textit{OSM}-у}
  \label{fig:osm_map_example}
\end{figure}

\textit{OSM} је 2004. године покренуо Стив Коуст (енг. \textit{Steve Coast}) са идејом креирања мапа за Уједињено Краљевство. У наредним годинама пројекат је постао глобалан и сада садржи податке целог света \cite{osm_wiki}.

\section{Елементи}
\label{sec:osm_elementi}

За моделовање података физичког света у оквиру \textit{OSM}-а се користе \textit{OSM}-елементи \cite{osm_wiki}. Постоје три врсте елемената и то су чворови (енг. \textit{nodes}), путање (енг. \textit{ways}) и релације (енг. \textit{relations}).

Сваки од елемената може имати придружену једну или више ознака (енг. \textit{tag}) чија је улога да опишу елемент коме припадају. Елементи \textit{OSM}-скупа се могу представити помоћу записа \textit{XML}  од којих је сваки одређен засебном \textit{XML}-ознаком \cite{osm_xml}. Сваки елемент у запису \textit{XML} поседује атрибуте који га описују. Постоје одређени атрибути који се налазе у сваком елементу:

\begin{itemize}
	\item \textbf{\textit{id}}, јединствен идентификатор елемента;
	\item \textbf{\textit{user}}, име корисника који је изменио елемент;
	\item \textbf{\textit{uid}}, идентификатор корисника који је изменио елемент;
	\item \textbf{\textit{timestamp}}, време последње промене елемента;
	\item \textbf{\textit{visible}}, знак који показује да ли је елемент видљив;
	\item \textbf{\textit{version}}, тренутна верзија елемента (почетна вредност је 1 и сваки пут када се изврши модификација елемента тај број се инкрементира);
	\item \textbf{\textit{changeset}}, идентификатор скупа промена у коме је елемент измењен.
\end{itemize}

Иако се подаци \textit{OSM} могу представити помоћу записа \textit{XML}, за обраду података је препоручен формат \textit{PBF} \cite{osm_pbf_format}. У односу на \textit{XML}, \textit{PBF}-фајл заузима мање меморије и има боље перформансе за читање и писање података. \textit{OSM}-фајлови формата \textit{PBF} имају екстензију \textit{*.osm.pbf}. 

\subsection{Ознаке}
\label{subsec:osm_tags}

Ознаке представљају опис \textit{OSM}-елемента коме припадају. Сваки елемент може имати нула, једну или више ознака \cite{osm_wiki}. Чине је две вредности, кључ, који мора бити јединствен унутар елемента ког ознака описује, и вредност. У коду \ref{lst:osm_tag_xml} је приказан пример ознака у формату \textit{XML}. Кључ и вредност су означени редом атрибутима \textit{k} и \textit{v}. Приказане ознаке припадају примеру чвора из кода \ref{lst:osm_node_xml} и показују да чвор означава саобраћајни знак.

\begin{lstlisting}[language=XML, caption={Пример \textit{OSM}-ознака у формату \textit{XML}}, label={lst:osm_tag_xml}]
<tag k="name" v="Neu Broderstorf"/>
<tag k="traffic_sign" v="city_limit"/>
\end{lstlisting}

\section{Чворови}
\label{sec:osm_nodes}

Чвор представља локацију на Земљиној површини и састоји се од две координате које представљају географску дужину и ширину \cite{osm_wiki}. Један чвор се може користити за дефиницију објекта на мапи, попут, на пример, клупе, статуе, хотела или ресторана.

У језику \textit{XML} чворови су представљени \textit{XML}-ознаком \textit{node} унутар које су угњеждене \textit{OSM}-ознаке које јој припадају. К\^{о}д \ref{lst:osm_node_xml} представља један чвор записан у формату \textit{XML}. Атрибути \textit{lat} и \textit{lon} представљају координате чвора на мапи. Чвор садржи две ознаке, које означавају да се на координатама чвора налази саобраћајни знак који представља улазак у насеље \textit{Neu Broderstorf}.

\begin{lstlisting}[language=XML, caption={Запис \textit{XML} \textit{OSM}-чвора који представља саобраћајни знак}, label={lst:osm_node_xml}]
<node id="1831881213" version="1" changeset="12370172" lat="54.0900666" lon="12.2539381" user="lafkor" uid="75625" visible="true" timestamp="2012-07-20T09:43:19Z">
  <tag k="name" v="Neu Broderstorf"/>
  <tag k="traffic_sign" v="city_limit"/>
 </node>
\end{lstlisting}

\section{Путање}
\label{sec:osm_ways}

Путање су уређене листе које садрже између 2 и 20000 чворова и представљају линеарне објекте на мапи, попут путева или река \cite{osm_wiki}. Такође, могу представљати и разне врсте површина, попут шума. У том случају су први и последњи елемент листе исти чвор. 

Путање су у формату \textit{XML} представљене листом идентификатора чворова које та путања садржи. Сваки чвор путање је записан \textit{XML}-ознаком \textit{nd} са атрибутом \textit{ref} унутар ког се налази идентификатор чвора. Поред идентификатора чворова, путања може садржати и \textit{OSM}-ознаке. \textit{XML}-ознака која означава путању је \textit{way}. У коду \ref{lst:osm_way_xml} је приказан пример путање која представља улицу. Унутар \textit{OSM}-ознаке путање је записано име улице, као и информација о томе да је улица једносмерна.

\begin{lstlisting}[language=XML, caption={Запис \textit{XML} \textit{OSM}-путањe која представља улицу}, label={lst:osm_way_xml}]
<way id="5090250" visible="true" timestamp="2009-01-19T19:07:25Z" version="8" changeset="816806" user="Blumpsy" uid="64226">
    <nd ref="822403"/>
    <nd ref="21533912"/>
    <nd ref="821601"/>
    <nd ref="21533910"/>
    <nd ref="135791608"/>
    <nd ref="333725784"/>
    <nd ref="333725781"/>
    <nd ref="333725774"/>
    <nd ref="333725776"/>
    <nd ref="823771"/>
    <tag k="highway" v="residential"/>
    <tag k="name" v="Clipstone Street"/>
    <tag k="oneway" v="yes"/>
  </way>
\end{lstlisting}

\section{Релације}
\label{sec:osm_relations}

Релације су структуре које представљају однос између \textit{OSM}-елемената \cite{osm_wiki}. Могу имати разна значења па су због тога описане \textit{OSM}-ознакама. Обично, свака релација поседује \textit{OSM}-ознаку која се зове \textit{type} и свака друга ознака те релације се интерпретира на основу њене вредности.

У формату \textit{XML}, релација се означава ознаком \textit{relation} и садржи чланове релације и \textit{OSM}-ознаке. Члан је одређен \textit{XML}-ознаком \textit{member} и садржи три атрибута:

\begin{itemize}
	\item \textbf{\textit{type}}, \textit{OSM}-тип члана, може бити \textit{node}, \textit{way} или \textit{relation};
	\item \textbf{\textit{ref}}, идентификатор елемента члана;
	\item \textbf{\textit{role}}, улога члана у релацији.
\end{itemize}

Репрезентација \textit{XML} релације која представља аутобуску линију приказана је у коду \ref{lst:osm_relation_xml}. У овом примеру, \textit{OSM}-чворови који припадају релацији представљају аутобуске станице. Поред чворова, релацији припада и једна путања, која приказује путању аутобуске линије. Ознаке релације приказују назив почетне и завршне локације линије, као и информације о превознику.

\begin{lstlisting}[language=XML, caption={Запис \textit{XML} \textit{OSM}-релације која представља аутобуску линију}, label={lst:osm_relation_xml}]
<relation id="13092746" visible="true" version="7" changeset="118825758" timestamp="2022-03-23T15:05:48Z" user="" uid="">
  <member type="node" ref="5690770815" role="stop"/>
  <member type="node" ref="5751940550" role="stop"/>
  ...
  <member type="node" ref="1764649495" role="stop"/>
  <member type="way" ref="96562914" role=""/>
  ...
  <member type="way" ref="928474550" role=""/>
  <tag k="from" v="Encre"/>
  <tag k="name" v="9-Montagnes de Guyane"/>
  <tag k="network" v="Agglo'bus"/>
  <tag k="not:network:wikidata" v="Q3537943"/>
  <tag k="operator" v="CACL"/>
  <tag k="ref" v="9"/>
  <tag k="route" v="bus"/>
  <tag k="to" v="Lyce Balata"/>
  <tag k="type" v="route"/>
 </relation>
\end{lstlisting}

% ============== ??? =====================
% pomeni leaflet za prikaz mapa. Ali to moze da se uradi u aplikacija sekciji
% mozda pasus za semanticki veb + osm. Ali to mozda i u zakljucku: https://wiki.openstreetmap.org/wiki/OSM_Semantic_Network
% ============== ??? =====================

\chapter{Опис апликације \textit{Geo-locator}}
\label{chp:app}

У овом поглављу ће детаљно бити описана израђена апликација за дистрибуирану обраду и графички приказ геопросторних података. Опис апликације укључује опис коришћених података, компоненти и технологија. Апликација је названа \textit{Geo-locator} и налази се на адреси \textit{https://github.com/davgav123/geo}.

Намена апликације је да филтрира геопросторне податке за државе Европе на такав начин да издвоји одређене битне локације, попут болница, апотека, ресторана и хотела. Издвојене локације за сваку државу се складиште и приказују на захтев корисника. 

Део апликације за дистрибуирану обраду података је израђен у програмском језику Скала, коришћењем алата \textit{Apache Spark}, док је за кориснички интерфејс коришћен језик \textit{JavaScript}. Скуп геопросторних података који садржи локације које треба издвојити је \textit{OpenStreetMap}. Из разлога што \textit{OSM}-скуп садржи неколико десетина гигабајта података, за израду апликације је коришћен облак компаније \textit{Amazon}.

\section{Рачунарство у облаку}
\label{sec:cloud}

Kako је \textit{OSM}-скуп података превелики да би се обрадио локално, у изради апликације је коришћен облак (енг. \textit{cloud}). Извршавање на oблаку (енг. \textit{cloud computing}) \cite{cloud_computing} представља закупљивање хардвера и софтвера које нуди провајдер, на захтев, преко интернета, где се плаћање извршава по количини искоришћених ресурса. На пример, преко облака је могуће закупити базу података која ће преко интернета бити доступна одмах и плаћање ће се извршавати док год се та база податка користи. Коришћење услуга облака је приказано на слици \ref{fig:cloud_comp_example}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.85\textwidth]{pictures/cloud_computing.png}
  \caption{Приказ коршћења услуга облака}
  \label{fig:cloud_comp_example}
\end{figure}

У изради апликације коришћен је Амазонов облак (енг. \textit{Amazon Web Services}), скраћено \textit{AWS}. Хардвер и софтвер који се може закупити од \textit{AWS}-а се назива сервис. Израђена апликација за дистрибуирану обраду података користи два сервиса, \textit{S3} \cite{s3} и \textit{EMR} \cite{emr}.

% можда ће бити 3, са EC2 (за приказ резултата итд), онда то додај

Сервис \textit{S3}, скрађено од \textit{Simple Storage Service}, се користи за поуздано складиштење фајлова на \textit{AWS}-у. Складиштени фајлови могу бити било ког формата и распоређени су у кофе (енг. \textit{bucket}), које се могу посматрати слично као директоријуми у фајл систему рачунара. У апликацији се \textit{S3} користи за складиштење \textit{OSM}-фајлова над којима се врши обрада и за складиштење резултата обраде.

Сервис \textit{EMR}, скраћено од \textit{Elastic Map Reduce}, представља екосистем \textit{Hadoop} на \textit{AWS}-у. Састоји се од машина којима се може бирати снага процесора и количина меморије, зависно од потребе. На \textit{EMR}-у се може инсталирати велики број апликација екосистема \textit{Hadoop}, укључујући \textit{Apache Yarn} и \textit{Apache Spark}. Апликација користи овај сервис приликом дистрибуиране обраде података.
 
\section{Подаци}
\label{sec:osm_spark_podaci}

У изради апликације су коришћена два скупа података. Први скуп представља \textit{OSM}-податке Европе и у њему се налазе информације о географским локацијама. Изабрани \textit{OSM}-скуп података је у формату \textit{PBF} (енг. \textit{Protocolbuffer Binary Format}) \cite{osm_pbf_format}. Пошто \textit{Apache Spark} нема уграђену функционалност за читање података у формату \textit{PBF}, подаци се морају пребацити у неки други формат, за који постоји једноставна интеграција са \textit{Spark}-ом. Један од тих формата је формат отвореног кода, дизајниран за брзо читање и уписивање података, \textit{Apache Parquet} \cite{apache_parquet}. Фајл формата \textit{PBF} се може изменити у \textit{parquet} коришћењем апликације \textit{osm-parquetizer} \cite{osm_parquetizer}. Ова апликација прима \textit{OSM}-скуп у формату \textit{PBF} и као резултат има три фајла у формату \textit{parquet}. Резултујући фајлови представљају одвојено  \textit{OSM}-чворове (са суфиксом \textit{node}), путање (са суфиксом \textit{way}) и релације (са суфиксом \textit{relation}) почетног \textit{PBF}-фајла. Како су за израду апликације \textit{Geo-locator} потребне само локације са описима, које садрже \textit{OSM}-чворови, релације и путање се могу одбацити. Укупна величина резултујућег скупа \textit{OSM}-чворова који представљају Европу је око 60 гигабајта.

Други скуп, \textit{GeoNames} \cite{geonames} садржи информације о државама света, укључујући њихове границе, популацију, главни град, валуту, позивни број и слично. Границе држава скупа \textit{GeoNames} су представљене полигонима којима су темена локације на географској мапи. Уколико се држава састоји из више целина, на пример острва, границе су представљене мултиполигоном чији су делови полигони који представљају једну целину државе. У супротном, границе су представљене једним полигоном. Скуп \textit{GeoNames} се састоји из два фајла. Први, \textit{shapes\_all\_low}, садржи границе држава, док други, \textit{country\_info}, садржи опште информације о државама, уључујући њихово име. Колона која их спаја представља јединствени идентификатор државе и назива се \textit{geoNameId}.

\section{Архитектура апликације}
\label{sec:app_aphi}

Апликација се састоји од три компоненте (слика \ref{fig:app_components}). Прва, компонента за обраду података, \textit{Geo-processor}, чита податке \textit{OSM} и скупа \textit{GeoNames} са локације на сервису \textit{S3}, обрађује их помоћу Скале, \textit{Spark}-а и сервиса \textit{EMR}, и након тога резултате уписује назад на \textit{S3}. 

Друга компонента, названа \textit{Geo-backend} представља сервер, који на захтев клијента чита обрађене податке и прослеђује их клијенту. Због високе цене обраде, подаци се не обрађују на сваки захтев клијента, већ се читају складиштени, већ обрађени подаци. Сервер апликацијe је написан у програмском језику Скала, коришћењем библиотеке \textit{Akka} \cite{scala_akka}, уз помоћ које се креирају сервер и постојећи \textit{http}-методи.

Последња компонента, клијент, названа \textit{Geo-frontend}, приказује мапу света, прима упит корисника и исцртава жељене резултате. Страница клијента је приказана на слици \ref{fig:app_front}. Написана је у програмском језику \textit{JavaScript} и за исцртавање географске мапе и приказ резултата користи библиотеку \textit{Leaflet} \cite{leaflet}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1\textwidth]{pictures/app_arch_components.png}
  \caption{Компоненте апликације}
  \label{fig:app_components}
\end{figure}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1\textwidth]{pictures/geo_frontend.png}
  \caption{Клијентска страница апликације}
  \label{fig:app_front}
\end{figure}

\section{Одређивање припадности локације држави}
\label{sec:poly_cont}

Проблем одређивања припадности локације држави је еквивалентан проблему одређивања припадности тачке полигону, где је локација тачка, а граница државе полигон или, за одређене државе, мултиполигон. Како је проблем припадности тачке полигону веома заступљен у рачунарској графици, постоји велики број алгоритама који га решавају. У овом раду су испробана три алгоритма и њихова имплементација се може пронаћи унутар класе \textit{Polygon} компоненте \textit{Geo-processor}. Ти алгоритми су:

\begin{itemize}
	\item Алгоритам \textit{Ray casting} \cite{inside_polygon};
	\item алгоритам заснован на сумирању углова \cite{inside_polygon};
	\item алгоритам доступан у оквиру Јава библиотеке \textit{awt} \footnote{имплементациони детаљи непознати}, у класи \textit{awt.Polygon} \cite{java_awt_polygon}.
\end{itemize}

%\textit{Ray casting} алгоритам \cite{inside_polygon}, алгоритам који се заснива на сумирању углова \cite{inside_polygon} и алгоритам доступан у оквиру Јава \textit{awt} библиотеке, унутар \textit{Polygon} класе \cite{java_awt_polygon}.

Алгоритам \textit{Ray casting} исцртава хоризонталне дужи из жељене тачке, такве да јој се други крај налази изван полигона. Након тога се пребројава број пресека исцртане дужи са свим страницама полигона. Уколико је број пресека паран, тачка се налази ван полигона, а уколико је непаран, тачка се налази у полигону. Из примера алгоритма приказаног на слици \ref{fig:ray_cast_algo_example} се може закључити да се тачке \textit{А} и \textit{Д} налазе унутар полигона, док су тачке \textit{Б} и \textit{Ц} изван. Недостатак алгоритма \textit{Ray casting} је појава грешака приликом одређивања припадности тачака које се налазе близу ивица полигона. %Може се користити за одређивање припадности тачке свакој врсти полигона.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.55\textwidth]{pictures/ray_cast_pic_example.png}
  \caption{Алгоритам \textit{Ray casting}}
  \label{fig:ray_cast_algo_example}
\end{figure}

Алгоритам заснован на сумирању углова сабира углове између жељене тачке и сваког пара темена полигона. Уколико је сума $2\pi$ онда се тачка налази унутар полигона, а уколико није онда се налази изван. Овај алгоритам функционише за све врсте полигона. Као и  \textit{Ray casting}, овај алгоритам може погрешно одредити припадност за тачке близу ивица полигона.

Алгоритми су тестирани над \textit{OSM}-скуповима који представљају Црну Гору и Словенију. Оба тест скупа садрже одређен број локација које не припадају државама које представљају, већ припадају њиховим суседима. То их чини повољним за тестирање, пошто се резултати алгоритама за припадност тачке полигону једноставно могу проверити исцртавањем на географској мапи. Локације из тест скупова су приказане црвеном бојом на слици \ref{fig:all_map_slo_mon_example}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1\textwidth]{pictures/mon_slo_totals.png}
  \caption{Локације из \textit{OSM}-скупова Црне Горе и Словеније коришћених за тестирање}
  \label{fig:all_map_slo_mon_example}
\end{figure}

%Резултати добијени применом алгоритама на поменуте скупове су приказани у табели \ref{tab:tabla_rez_poly_cont_algor} и означавају удео локација које се налазе унутар граница у односу на цео скуп, за сваки алгоритам. Резултати су слични, али алгоритам заснован на сабирању углова додељује већи број тачака границама држава у односу на остала два.

%\begin{table}[h!]
%\begin{center}
%\begin{tabular}{|c|c|c|c|c|} \hline
%\textbf{ } & \textbf{Удео локација које} & \textbf{Удео локација које} \\
%\textbf{Алгоритам} & \textbf{припадају Црној Гори} \textbf{припадају Словенији} \\ \hline
%\textit{Ray casting} & 0.775 & 0.950 \\ \hline
%Библиотека \textit{Awt} & 0.757 & 0.951 \\ \hline
%Сумирање углова & 0.775 & 0.956 \\ \hline
%\end{tabular}
%\caption{Удео локација које се налазе унутар границе држава}
%\label{tab:tabla_rez_poly_cont_algor}
%\end{center}
%\end{table}

Добијени резултати за сваки алгоритам су углавном добри али постоје одређени недостаци. Сваки алгоритам је погрешно одредио припадност малом броју локација које се налазе близу обала мора. Поред тога, код сваког алгоритма постоје мање грешке за локације близу граница са другим државама. За разлику од друга два алгоритма, \textit{Ray casting} је погрешно одредио припадност одређеном броју тачака на југоистоку Словеније. Због добијених резултата, у изради апликације је коришћен алгоритам заснован на сумирању углова. Резултати примене изабраног алгоритма на скупове за тестирање су приказани црвеном бојом, и на слици \ref{fig:not_slo_mon_example} представљају локације ван граница држава, док на слици \ref{fig:slo_mon_example} представљају локације унутар граница.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1\textwidth]{pictures/not_slo_mon_sum_angles.png}
  \caption{Резултат за локације изван држава за алгоритам заснован на сумирању углова}
  \label{fig:not_slo_mon_example}
\end{figure}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1\textwidth]{pictures/slo_mon_sum_angles.png}
  \caption{Резултат за локације унутар држава за алгоритам заснован на сумирању углова}
  \label{fig:slo_mon_example}
\end{figure}

\section{Обрада геопросторних података \textit{Spark}-ом}
\label{sec:osm_spark_obrada}

Након трансформисања \textit{OSM}-фајла из формата \textit{PBF} у формат \textit{parquet} и постављања \textit{parquet} фајла на \textit{S3}, може се почети са дистрибуираном обрадом података. Компонента апликације која обрађује податке је \textit{Geo-processor}. Написана је у верзији 2.12.12 програмског језика Скала коришћењем верзије 3.1.2 алата \textit{Apache Spark}. Верзије су изабране због компатибилности. Изабрана верзија \textit{Spark}-а је компатибилна са коришћеном верзијом \textit{AWS} сервиса, док је верзија Скале компатибилна са верзијом \textit{Spark}-а.

Подаци се обрађују на верзији 6.4.0 \textit{EMR}-кластера. Одабрана верзија садржи инсталиране верзије 3.1.2 \textit{Spark}-а и 3.2.1 \textit{Hadoop}-а. Кластер се састоји од четири машине од којих је једна именски чвор, док су остале чворови података. Свака од машина садржи осам језгара процесора и тридесет два гигабајта радне меморије. \textit{Spark} је конфигурисан тако да има шест извршилаца са по четири језгра процесора и шеснаест гигабајта меморије. Као менаџер ресурса се користи \textit{Apache Yarn}.
Трајање обраде података, које укључује и читање и упис обрађених података на \textit{S3} је осам сати и тридесет седам минута.

Изворни к\^{о}д намењен за обраду података се налази унутар модула	 \textit{geo} компоненте \textit{Geo-processor}, у објекту \textit{GeoDataProcessor}. Обрада се може поделити на два дела. Први чита податке и одређује која локација скупа припада којој држави, док друга за сваку државу филтрира жељену врсту локација након чега врши упис података. Оба дела су представљена у функцији \textit{processGeoData}, која као аргументе прима иницијализовану инстанцу \textit{Spark}-а, локацију скупа геопросторних података које треба обрадити и локацију у коју ће коначан резултат бити уписан. Приказ позива функције се налази у класи \textit{Main} компоненте \textit{Geo-processor} и приказан је у коду \ref{lst:app_code_main_processGeoData}. Путање представљају локације на сервису \textit{S3}, где је \textit{geo-master-496542722941} име кофе, док остатак путање представља путању до фајла унутар кофе.

\begin{lstlisting}[caption={Позивање функције која започиње обраду података}, language=Scala, label={lst:app_code_main_processGeoData}]
processGeoData(
  spark,
  "s3a://geo-master-496542722941/osm-data/europe/europe-latest.osm.pbf.node.parquet",
  "s3a://geo-master-496542722941/osm-data/countries/countries-data"
)
\end{lstlisting}

\textit{OSM}-скуп чворова Европе, након примене апликације \textit{osm-parquetizer}, поседује шему приказану у коду \ref{lst:app_code_node_schema}. Скуп се учитава унутар функције \textit{getNodes} и из њега се трансформацијом \textit{select} издвајају потребне информације, географска дужина и ширина, као и скуп \textit{OSM}-ознака, у коме се налазе информације о томе шта се налази на координатама. Након тога се трансформацијом \textit{where} подаци филтрирају тако што се одбацују сви редови којима су географска ширина и дужина \textit{null} као и редови којима је скуп ознака празан. Имплементација функције \textit{getNodes} се налази у коду \ref{lst:app_code_getNodes}

\begin{lstlisting}[caption={Шема \textit{OSM}-скупа чворова након примене апликације \textit{osm-parquetizer}}, language=Scala, label={lst:app_code_node_schema}]
|-- id: long (nullable = true)
|-- version: integer (nullable = true)
|-- timestamp: long (nullable = true)
|-- changeset: long (nullable = true)
|-- uid: integer (nullable = true)
|-- user_sid: string (nullable = true)
|-- tags: array (nullable = true)
|    |-- element: struct (containsNull = true)
|    |    |-- key: string (nullable = true)
|    |    |-- value: string (nullable = true)
|-- latitude: double (nullable = true)
|-- longitude: double (nullable = true)
\end{lstlisting}

\begin{lstlisting}[caption={Функција која учитава податке и извршава иницијално филтрирање колона и редова}, language=Scala, label={lst:app_code_getNodes}]
def getNodes(spark: SparkSession, pathToCountryFile: String): DataFrame = {
  val nodes: DataFrame = spark
    .read
    .format("parquet")
    .load(pathToCountryFile)

  nodes.select(
    col("latitude"),
    col("longitude"),
    col("tags")
  )
    .where("latitude is not null and longitude is not null")
    .where(size(col("tags")) =!= 0)
}
\end{lstlisting}

Након учитавања података, потребно је доделити одговарајућу државу за сваку локацију. Да би се тај корак извршио, морају се учитати и обрадити подаци скупа \textit{GeoNames}, који се састоје из два фајла, сачувана на сервису \textit{S3}. Први је \textit{shapes\_all\_low} који је у формату \textit{Tab Separated Values}, скраћено \textit{TSV}, и садржи две колоне. Прва је \textit{geoNameId}, док је друга \textit{geoJSON}, у формату \textit{JSON}. \textit{JSON} садржи два кључа и први је ознака, названа \textit{type}, која показује да ли су границе представљене једним полигоном (ознака \textit{Polygon}) или са више полигона (ознака \textit{MultiPolygon}). Други \textit{JSON} кључ, назван \textit{coordinates}, садржи листу координата које означавају полигоне. Пример редова овог скупа се налази у коду \ref{lst:app_code_shapes_all_low_example}.

\begin{lstlisting}[caption={Упрошћени пример редова фајла \textit{shapes\_all\_low}}, language=Scala, label={lst:app_code_shapes_all_low_example}]
geoNameId	geoJSON
49518	    {"type":"Polygon","coordinates":[[[29.96,-2.327],...,[29.438,-2.798]]]}
51537	    {"type":"MultiPolygon","coordinates":[[[[42.322,-0.659],...,[43.451,11.491]]]]}
\end{lstlisting}

Да би се информације из колоне \textit{geoJSON} извукле у засебне колоне, потребно је издвојити ту колону, направити нови \textit{DataFrame} од ње и додати колону \textit{geoNameId}. Процес трансформације колоне \textit{geoJSON} се налази у функцији \textit{prepareBorderData} и приказан je у коду \ref{lst:app_code_prepare_borders}. Исти процес је приказан и на слици \ref{fig:app_code_transofrm_prepare_borders}. Први корак је прочитати фајл у \textit{DataFrame} и након тога од њега креирати нови, пребацивањем колоне \textit{geoJSON} у засебан \textit{DataFrame}. На такав начин се добија \textit{DataFrame} са две колоне, \textit{type} и \textit{coordinates}. На њега се трансформацијом \textit{withColumn} додаје још једна колона која ће се користити у спајању и која за сваки ред има вредност његовог редног броја. Након тога се из почетно прочитаног фајла \textit{shapes\_all\_low}, издваја колона \textit{geoNameId}, трансформацијом \textit{drop}, којом се брише колона \textit{geoJSON} и тако се конструише још један нови \textit{DataFrame}. На њега се трансформацијом \textit{withColumn} додаје колона за спајање, која за сваки ред има вредност његовог редног броја. Након тога се два добијена \textit{DataFrame}-а спајају преко колоне за спајање и колона за спајање се брише. Резултат је \textit{DataFrame} са три колоне, \textit{geoNameId}, \textit{type} и \textit{coordinates}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1\textwidth]{pictures/borders_file_thingy.png}
  \caption{Приказ трансформација над скупом \textit{GeoNames} података који садржи границе}
  \label{fig:app_code_transofrm_prepare_borders}
\end{figure}

Добијени \textit{DataFrame} поседује информације о границама, али не садржи имена држава, већ само њихов идентификатор. Имена се налазе у фајлу \textit{country\_info}. Након читања тог фајла, добијени \textit{DataFrame} треба спојити са претходним и из спојеног \textit{DataFrame}-а извући потребне колоне, \textit{country} која представља име државе, \textit{type} која означава да ли су границе полигон или мултиполигон и \textit{coordinates} у којој се налазе координате граница. На крају се из добијеног скупа филтрирају државе које се не разматрају, што су у овом случају све државе које се не налазе у Европи. Имена европских државе се налазе у функцији \textit{getEuropeanCountries}. Цео процес је приказан у коду \ref{lst:app_code_prepare_borders} у коме се налази функција \textit{prepareBorderData}.

\begin{lstlisting}[caption={Функција која припрема \textit{DataFrame} у коме се налазе информације о границама држава}, language=Scala, label={lst:app_code_prepare_borders}]
private def prepareBorderData(spark: SparkSession): DataFrame = {
  val pathToBordersFile = "s3a://geo-master-496542722941/geo-names/shapes_all_low.txt"
  val pathToInfoFile = "s3a://geo-master-496542722941/geo-names/country_info.txt"

  val countryBordersRaw: DataFrame = spark
    .read
    .format("csv")
    .option("delimiter", "\t")
    .option("header", "true")
    .option("inferSchema", "true")
    .load(pathToBordersFile)

  import spark.implicits._ // need this in order to cast json to string
  val parsedJson: DataFrame = spark.read.json(countryBordersRaw.select(col("geoJSON")).as[String])
    .withColumn("join_column", monotonically_increasing_id())

  val prepareBordersForJoin: DataFrame = countryBordersRaw
    .withColumn("join_column", monotonically_increasing_id())
    .drop(col("geoJSON"))

  val countryBorders: DataFrame = prepareBordersForJoin
    .join(parsedJson, "join_column")
    .select(
      col("geoNameId"),
      col("type"),
      flatten(col("coordinates")).as("coordinates")
    )

    val countryToId: DataFrame = spark.read
    .format("csv")
    .option("delimiter", "\t")
    .option("header", "true")
    .option("inferSchema", "true")
    .load(pathToInfoFile)
    .select(col("geonameid").as("id"), col("Country"))

  val borders: DataFrame = countryBorders
    .join(
      countryToId,
      countryBorders("geoNameId") === countryToId("id"),
      "inner"
    )
    .select(
      lower(col("Country")).as("country"),
      col("type").as("border_type"),
      col("coordinates").as("border_coordinates")
    )

  val selectedCountries: Array[String] = getEuropeanCountries
  borders
    .filter(col("country").isInCollection(selectedCountries))
}
\end{lstlisting}

% промењен УДФ описан у спарк секцији. Коришћене броадцаст варс

За одређивање припадности локације држави, конструише се \textit{udf}, приказан у коду \ref{lst:app_code_belongstocountry}. Улога \textit{udf}-а је да за прослеђене географску ширину и дужину, одреди којој држави припадају. Повратна вредност је име државе, а уколико локација не припада ниједној држави, враћа се вредност ,,$-$``. Листа \textit{iterableBorders} је \textit{broadcast} променљива и садржи полигоне \textit{GeoNames} скупа који представљају границе, док функција \textit{isInsideBorder} за сваку локацију проверава којој држави припада тако што итерира кроз сваку границу и проверава припадност алгоритмом заснованим на сумирању углова.

\begin{lstlisting}[caption={Функција која додељује државу локацији}, language=Scala, label={lst:app_code_belongstocountry}]
val belongsToCountryFunction: (Double, Double) => String = (lat: Double, lon: Double) => {
  var belongs_to = "-"
  for ((country, borders) <- iterableBorders.value) {
    if (isInsideBorder(lat, lon, borders)) {
      belongs_to = country
    }
   }

  belongs_to
}
\end{lstlisting}

Процес додељивања државе локацији се извршава унутар функције приказане у коду \ref{lst:app_code_mapcoordstocountry}. Након извршеног додељивања, из \textit{DataFrame}-а се избацују све локације којима није додељена држава. На крају се извршава партиционисање података у односу на државу, трансформацијом \textit{repartition}. Резултујући \textit{DataFrame} ове функције садржи локацију, тачније географску ширину и дужину, \textit{OSM}-ознаке, као и ознаку којој држави локација припада. Његова шема је приказана у коду \ref{lst:app_code_countrydf_schema}.

\begin{lstlisting}[caption={Функција \textit{mapCoordinatesToCountry}}, language=Scala, label={lst:app_code_mapcoordstocountry}]
def mapCoordinatesToCountry(spark: SparkSession, countryFilePath: String): DataFrame = {
  val iterableBorders = spark.sparkContext.broadcast(
    makeBordersIterable(prepareBorderData(spark))
  )

  val belongsToCountryFunction: (Double, Double) => String = (lat: Double, lon: Double) => {
    var belongs_to = "-"
    for ((country, borders) <- iterableBorders.value) {
      if (isInsideBorder(lat, lon, borders)) {
        belongs_to = country
      }
    }

    belongs_to
  }

  val belongsToCountry = udf[String, Double, Double](belongsToCountryFunction)

  val osmData = getNodes(spark, countryFilePath)
    .withColumn(
      "country",
      belongsToCountry(
        col("latitude"),
        col("longitude")
      )
    )

  osmData
    .filter(col("country") =!= lit("-"))
    .repartition(col("country"))
}
\end{lstlisting}

\begin{lstlisting}[caption={Шема \textit{DataFrame}-а након додељивања држава локацијама}, language=Scala, label={lst:app_code_countrydf_schema}]
 |-- latitude: double (nullable = true)
 |-- longitude: double (nullable = true)
 |-- tags: array (nullable = true)
 |    |-- element: struct (containsNull = true)
 |    |    |-- key: binary (nullable = true)
 |    |    |-- value: binary (nullable = true)
 |-- country: string (nullable = true)
\end{lstlisting}

Након одређивања припадности, потребно је за сваку државу изабрати жељену врсту локација. Филтрирање се извршава у односу на колону \textit{tags} \textit{DataFrame}-а. Пример садржаја колоне \textit{tags} се налази у коду \ref{lst:code_app_tags_col_values}. Састоји се од низа кључ-вредност парова, од којих су за одабир жељених врста локације потребне само вредности. Оне се могу издвојити трансформацијом \textit{withColumn} и применом функције \textit{expr}, која користи функцију \textit{transform} за трансформисање кључ-вредност парова (к\^{о}д \ref{lst:code_app_with_col_expr_transform}).

\begin{lstlisting}[caption={Пример вредности колоне \textit{tags}}, language=Scala, label={lst:code_app_tags_col_values}]
+----------------------------------------------------+
|tags                                                |
+----------------------------------------------------+
|[{access, yes}, {amenity, parking}, {parking, lane}]|
|[{amenity, restaurant}, {outdoor_seating, yes}]     |
|[{name, The Tesla Art Hostel}, {tourism, hostel}]   |
|[{amenity, hospital}, {healthcare, hospital}]       |
|[{name, The Black Turtle Pub I}, {amenity, pub}     |
|[{name, Picerija}, {amenity, cafe}]                 |
+----------------------------------------------------+
\end{lstlisting}

\begin{lstlisting}[caption={Конструкција низа вредности колоне \textit{tags}}, language=Scala, label={lst:code_app_with_col_expr_transform}]
countryDF
  .withColumn(
    "tag_values",
    expr("transform(tags, x -> x.value)").cast(ArrayType(StringType))
  )
\end{lstlisting}

Следећи корак је филтрирање добијеног низа вредности ознака. Слично као код одређивања припадности локације држави, за филтрирање жељених локацијa се користи \textit{udf}, приказан у коду \ref{lst:app_code_filter_tag_vals_func}. Функционише тако што тражи пресек између жељених врста локација које се налазе у \textit{broadcast} променљивој \textit{conditions} и низа вредности ознака. Уколико пресек не постоји, функција враћа вредност ,,\textit{x}``, а уколико постоји, функција враћа врсту локације. Резултат је нова колона названа \textit{condition}. Након одређивања врсте локације, трансформацијом \textit{filter} се уклањају сви редови који садрже вредност ,,\textit{x}``. Све операције за филтрирање података се налазе унутар функције \textit{applyFilters} приказане у коду \ref{lst:app_code_apply_filters}.

\begin{lstlisting}[caption={Функција која одређује да ли је локација жељеног типа}, language=Scala, label={lst:app_code_filter_tag_vals_func}]
val filterTagValues: Array[String] => String = (tagValues: Array[String]) => {
  val intersection = tagValues.toSet.intersect(conditions.value)
  if (intersection.isEmpty) {
    "x"
  } else {
    intersection.head
   }
}
\end{lstlisting}

\begin{lstlisting}[caption={Функција \textit{applyFilters}}, language=Scala, label={lst:app_code_apply_filters}]
def applyFilters(spark: SparkSession, countryDF: DataFrame): DataFrame = {
  val conditions = spark.sparkContext.broadcast(
    Set(
      "hospital", "pharmacy", "hotel",
      "hostel", "bar", "cafe", "pub",
      "nightclub", "restaurant", "parking"
  ))

  val filterTagValues: Array[String] => String = (tagValues: Array[String]) => {
    val intersection = tagValues.toSet.intersect(conditions.value)
    if (intersection.isEmpty) {
      "x"
    } else {
      intersection.head
    }
  }

  val filterFunc = udf[String, Array[String]](filterTagValues)

  countryDF
    .withColumn(
      "tag_values",
      expr("transform(tags, x -> x.value)").cast(ArrayType(StringType))
    )
    .withColumn(
      "condition", filterFunc(col("tag_values"))
    )
    .filter(col("condition") =!= lit("x"))
}
\end{lstlisting}

Након филтрирања, добијене податке треба сачувати. Чување се извршава у функцији \textit{processGeoData} (к\^{о}д \ref{lst:app_code_process_geo_data}), позваној у коду \ref{lst:app_code_main_processGeoData}. Из података се прво извлаче жељене колоне, а затим се подаци чувају у формату \textit{parquet}. Пре чувања, подаци се партиционишу по колонама \textit{country} и \textit{condition} функцијом \textit{partitionBy}. Пример структуре излазног директоријума за државе Шпанију и Португал и за локације болница и хотела се налази у коду \ref{lst:app_code_partition_by_countries}. Географске ширине и дужине се налазе у крајњим \textit{parquet} фајловима, док се информације о држави и жељеној локацији налазе у именима директоријума који садрже \textit{parquet} фајлове. Након чувања, подаци су спремни и могу се користити за приказивање на географској мапи.

\begin{lstlisting}[caption={Функција \textit{processGeoData}}, language=Scala, label={lst:app_code_process_geo_data}]
def processGeoData(spark: SparkSession, pathToDataFile: String, pathToOutFile: String): Unit = {
  val mapped = mapCoordinatesToCountry(spark, pathToDataFile)

  applyFilters(mapped)
    .select(
      col("latitude"),
      col("longitude"),
      col("country"),
      col("condition")
    )
    .write
    .partitionBy("country", "condition")
    .mode(SaveMode.Overwrite)
    .parquet(pathToOutFile)
}
\end{lstlisting}

\begin{lstlisting}[caption={Структура директоријума партиционисаног по државама и врстама локација}, language=Scala, label={lst:app_code_partition_by_countries}]
|-- country=portugal
|   |-- condition=hospital
|   |   |-- part-00000-c55ece3af5a5.c000.snappy.parquet
|   |   |-- part-00001-c55ece3af5a5.c000.snappy.parquet
|   |-- condition=hotel
|   |   |-- part-00000-c55ece3af5a5.c000.snappy.parquet
|   |   |-- part-00001-c55ece3af5a5.c000.snappy.parquet
|-- country=spain
    |-- condition=hospital
    |   |-- part-00000-f558ba92bda6.c000.snappy.parquet
    |   |-- part-00001-f558ba92bda6.c000.snappy.parquet
    |-- condition=hotel
        |-- part-00000-f558ba92bda6.c000.snappy.parquet
        |-- part-00001-f558ba92bda6.c000.snappy.parquet
\end{lstlisting}

\section{Сервер апликације}
\label{sec:app_server}

Улога сервера апликације је да покрене сервер, прима захтеве \textit{GET} клијента, обради их и пошаље резултат. Креирање сервера и обрада захтева \textit{GET} је имплементирана преко модула \textit{http} библиотеке \textit{Akka}, док се обрада извршава преко \textit{Spark}-а. Креирање захтева \textit{GET} је приказано у коду \ref{lst:app_code_create_get}. Извршава се преко функције \textit{path}, чији је аргумент ниска која означава путању до захтева. Параметри захтева се задају функцијом \textit{parameters} док је повратна вредност функције одговор на захтев. У креираној функцији одговор је у формату \textit{JSON}. Улога \textit{Spark}-а у функцији \textit{readData} је да прочита жељене локације креиране од стране компоненте \textit{Geo-processor} и пребаци их у низ, који се као одговор шаље клијенту.

\begin{lstlisting}[caption={Имплементација функције која прима и обрађује захтев \textit{GET}}, language=Scala, label={lst:app_code_create_get}]
val route: Route = path("selection") {
  concat {
    cors() {
      get {
        parameters('country.as[String], 'param.as[String]) { (country, param) =>
          complete {
            val coords = readData(spark, country, param)
            HttpEntity(ContentTypes.`application/json`, s"""${coords.toJson}""")
          }
        }
      }
    }
  }
}

def readData(spark: SparkSession, country: String, cond: String): Array[Array[Double]] = {
  val dataPath = "/path/to/data/dir/"
  val countryFilePath = dataPath + s"country=$country/condition=$cond"

  spark
    .read
    .parquet(countryFilePath)
    .collect()
    .map(row => Array(row(0).asInstanceOf[Double], row(1).asInstanceOf[Double]))
}
\end{lstlisting}

На крају се направљена путања везује за инстанцу сервера, функцијом \textit{bind}. Сервер се налази на локацији \textit{localhost}, на порту \textit{8080} и покреће се функцијом \textit{newServerAt}, објекта \textit{Http}, библиотеке \textit{Akka} \cite{using_akka_http}. Имплементација сервера је приказана у коду \ref{lst:app_code_server_sturtup}.

\begin{lstlisting}[caption={Имплементација сервера}, language=Scala, label={lst:app_code_server_sturtup}]
val bindingFuture = Http().newServerAt("localhost", 8080)
  .bind(route)

println(s"Server is now online\nPress RETURN to stop...")
StdIn.readLine()
bindingFuture
  .flatMap(_.unbind())
  .onComplete(_ => {
     spark.close()
     system.terminate()
  })
\end{lstlisting}


\section{Клијент апликације}
\label{sec:app_client}

Клијент шаље захтеве \textit{GET} серверу и приказује резултат на географској мапи. Слање захтева се извршава уносом жељених параметара и притиском на дугме \textit{Submit} (слика \ref{fig:app_code_request_bar_front}). Притиском на дугме се креира захтев \textit{http} ка адреси сервера. За слање захтева се користи objekat \textit{XMLHttpRequest}. Када сервер пошаље резултате клијенту, он исцртава жељене локације црвеном бојом на мапи.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1\textwidth]{pictures/frontend_request_bar.png}
  \caption{Место за унос и слање захтева ка серверу}
  \label{fig:app_code_request_bar_front}
\end{figure}

За исцртавање мапе се користи библиотека \textit{Leaflet}. Иницијално се приказује мапа целе Европе, али се при исцртавању жељених локација мапа увеличава на приказ изабране државе.

\section{Приказ резултата}
\label{sec:rezultat}

У овом одељку су приказани примери крајњег резултата рада апликације. У примерима на сликама \ref{fig:app_code_italy_hotel}, \ref{fig:app_code_greece_restaurants}, \ref{fig:app_code_uk_pubs} и \ref{fig:app_code_switzerland_pharmacies} је приказана клијентска страница апликације са исцртаним локацијама. Приказане државе и локације су изабране да би се илустровале различите опције које корисник може да изабере. 

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.9\textwidth]{pictures/italy_hotels.png}
  \caption{Хотели у Италији}
  \label{fig:app_code_italy_hotel}
\end{figure}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.9\textwidth]{pictures/greece_restaurants.png}
  \caption{Ресторани у Грчкој}
  \label{fig:app_code_greece_restaurants}
\end{figure}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.9\textwidth]{pictures/uk_pubs.png}
  \caption{Пабови у Уједињеном Краљевству}
  \label{fig:app_code_uk_pubs}
\end{figure}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.9\textwidth]{pictures/switzerland_pharmacies.png}
  \caption{Апотеке у Швајцарској}
  \label{fig:app_code_switzerland_pharmacies}
\end{figure}

Одређивање припадности локација држави је било успешно за већину држава Европе. Међутим, како алгоритми за одређивање припадности тачке полигону нису савршени, дошло је до појаве грешака код мањих држава. Алгоритам је потпуно занемарио Сан Марино, и доделио све тачке које му припадају Италији (слика \ref{fig:app_code_san_marino_italy}). Такође, појављују се грешке код државе Монако, чији је велики број тачака припојен Француској. Припадност локација за остале мање државе Европе (Луксембург, Малта, Андора и Лихтенштајн) је одређена без грешака.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.9\textwidth]{pictures/san_marino_italy_errors.png}
  \caption{Сан Марино када се одабере приказ ресторана у Италији}
  \label{fig:app_code_san_marino_italy}
\end{figure}

\chapter{Закључак}
\label{chp:zakljucak}

У раду су описане особине и основни принципи програмског језика Скала. Уз опис су приложени и конкретни примери. У овом програмском језику је написана апликација која је циљ овог рада али и \textit{Apache Spark}, који се користи за дистрибуирану обраду података. Описани су основни концепти \textit{Apache Spark}-а, попут архитектуре, партиционисања података, кеширања, трансформација и акција. Поред концепата, детаљније су описане две компоненте \textit{Spark}-а за моделовање података \textit{RDD} и \textit{DataFrame}.

Приказана је и мотивација за коришћење дистрибуираних система као и њихова организација. Описан је дистрибуирани фајл систем \textit{HDSF}, централни део екосистема \textit{Hadoop} ког поред \textit{HDFS}-a чине и остале апликације разних намена, попут \textit{Apache Yarn}-а, \textit{Flume}-а, \textit{Hive}-a и \textit{Pig}-а. Приказана је и прва парадигма за дистрибуирану обраду података, \textit{MapReduce}-а, као и њени недостаци.

Имплементирана је апликација за дистрибуирану обраду скупа геопросторних података \textit{OpenStreetMap}. Обрада се извршава на екосистему \textit{Hadoop} имплементираном од стране \textit{AWS}-а, сервису \textit{EMR}. За обраду података се користе \textit{Apache Spark} и програмски језик Скала. Намена апликације је да филтрира геопросторне податке тако што ће за сваку државу европе издвојити локације здравствених објеката, хотела, хостела, барова, ресторана и других битних туристичких локација које се унутар ње налазе, да би се те локације касније приказале на географској мапи. За приказ локација на географској мапи се користи језик \textit{JavaScript} и библиотека \textit{Leaflet}.

Апликацијом је постигнут жељени резултат, иако се појављују грешке за локације малих држава Европе, Сан Марина и Монака. Време извршавања обраде података је задовољавајуће, али је потребно истражити да ли је могуће побољшање перформанси. Број понуђених опција за жељене локације садржи десет врста локација, али се једноставно може проширити, на пример додавањем религијских објеката, музеја и других туристичких атракција. Клијент и сервер компоненте су једноставне и имају добре перформансе.

Постоји неколико начина на које се апликација може унапредити. На пример, поред филтрирања локација по државама, филтрирање се може извршити и по регијама држава или градовима. Такође, могуће је и пратити тренутну локацију корисника и на основу ње приказивати филтриране локације. Да би подаци увек били ажурни потребно је направити аутоматизован систем који ће реаговати на објављивање сваке нове верзије скупа \textit{OpenStreetMap} и поново га филтрирати. Такође, потребно је истражити да ли је могуће унапређење перформанси коришћењем других технологија за дистрибуирану обраду података уместо \textit{Spark}-а, попут  \textit{Apache Sedona}-е \cite{apache_sedona}.

% jos stvari: vise filtera i vise drzava ali zbog performansi smanjeno

% potencijalne nadogradnje:
% napraviti da radi za posebne gradove/regije/pokrajne
% nadograditi da radi sa semantickim vebom mozda
% napraviti pipeline koji skuplja nove OSM podatke kada stignu i pravi nove rezultate od toga
% da se doda lokacija pa da na osnovu toga izbacuje

% na svoju sezonsku, R desno mesto 7 ------------------------------------------------------------------------------
% Literatura
% ------------------------------------------------------------------------------
\literatura

% ==============================================================================
% Završni deo teze i prilozi
\backmatter
% ==============================================================================

% ------------------------------------------------------------------------------
% Biografija kandidata
\begin{biografija}
\textbf{Давид Гавриловић}, рођен је 29.10.1996. у Чачку. Смер Информатика на Математичком факултету Универзитета у Београду је уписао 2015. године, а завршио 2019. Након тога је на истом факултету уписао мастер студије информатике. У новембру 2020. године је почео са радом у компанији \textit{Grid Dynamics} и од тад ради као \textit{Data Engineer}. Тренутно ради у тиму који развија и одржава инфраструктуру и сервисе које користе \textit{data science} и \textit{data analyst} тимови. Интересује се за обраду великих података, машинско учење и рад са геопросторним подацима.
\end{biografija}
% ------------------------------------------------------------------------------

\end{document} 
